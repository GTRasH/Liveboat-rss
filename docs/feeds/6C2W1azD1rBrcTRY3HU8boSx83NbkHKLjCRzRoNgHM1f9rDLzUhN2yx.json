{"id":"6C2W1azD1rBrcTRY3HU8boSx83NbkHKLjCRzRoNgHM1f9rDLzUhN2yx","title":"MLOps.community","displayTitle":"Podcast - MLOps","url":"https://anchor.fm/s/174cb1b8/podcast/rss","feedLink":"https://mlops.community/","isQuery":false,"isEmpty":false,"isHidden":false,"itemCount":7,"items":[{"title":"Performance Optimization and Software/Hardware Co-design across PyTorch, CUDA, and NVIDIA GPUs","url":"https://podcasters.spotify.com/pod/show/mlops/episodes/Performance-Optimization-and-SoftwareHardware-Co-design-across-PyTorch--CUDA--and-NVIDIA-GPUs-e3fi5uf","date":1771965862,"author":"Demetrios","guid":355,"unread":true,"content":"<p>, Computer History Museum , come join us while there are still tickets left.</p><p> is currently focused on building and scaling high-performance AI systems, writing and teaching about AI infrastructure, helping organizations adopt generative AI and performance engineering principles on AWS, and fostering large developer communities around these topics.</p><p>Performance Optimization and Software/Hardware Co-design across PyTorch, CUDA, and NVIDIA GPUs // MLOps Podcast #363 with Chris Fregly, Founder, AI Performance Engineer, and Investor</p><p>In today’s era of massive generative models, it's important to understand the full scope of AI systems' performance engineering. This talk discusses the new O'Reilly book, AI Systems Performance Engineering, and the accompanying GitHub repo (<a href=\"https://github.com/cfregly/ai-performance-engineering\" target=\"_blank\" rel=\"ugc noopener noreferrer\">https://github.com/cfregly/ai-performance-engineering</a>). </p><p>This talk provides engineers, researchers, and developers with a set of actionable optimization strategies. You'll learn techniques to co-design and co-optimize hardware, software, and algorithms to build resilient, scalable, and cost-effective AI systems for both training and inference. </p><p>Chris Fregly is an AI performance engineer and startup founder with experience at AWS, Databricks, and Netflix. He's the author of three (3) O'Reilly books, including Data Science on AWS (2021), Generative AI on AWS (2023), and AI Systems Performance Engineering (2025). He also runs the global AI Performance Engineering meetup and speaks at many AI-related conferences, including Nvidia GTC, ODSC, Big Data London, and more.</p><p>~~~~~~~~ ✌️Connect With Us ✌️ ~~~~~~~</p><p>[00:00] SageMaker HyperPod Resilience</p><p>[00:27] Book Creation and Software Engineering</p><p>[04:57] Software Engineers and Maintenance</p><p>[11:49] AI Systems Performance Engineering</p><p>[22:03] Cognitive Biases and Optimization / \"Mechanical Sympathy\"</p><p>[29:36] GPU Rack-Scale Architecture</p><p>[33:58] Data Center Reliability Issues</p><p>[43:52] AI Compute Platforms</p><p>[49:05] Hardware vs Ecosystem Choice</p><p>[1:00:05] Claude vs Codex vs Gemini</p><p>[1:14:53] Kernel Budget Allocation</p><p>[1:18:49] Steerable Reasoning Challenges</p><p>[1:24:18] Data Chain Value Awareness</p>","contentLength":2104,"flags":null,"enclosureUrl":"https://anchor.fm/s/174cb1b8/podcast/play/115987855/https%3A%2F%2Fd3ctxlq1ktw2nl.cloudfront.net%2Fstaging%2F2026-1-24%2F418748429-44100-2-c03acb299ff36.mp3","enclosureMime":"","commentsUrl":null},{"title":"Serving LLMs in Production: Performance, Cost & Scale // CAST AI Roundtable","url":"https://podcasters.spotify.com/pod/show/mlops/episodes/Serving-LLMs-in-Production-Performance--Cost--Scale--CAST-AI-Roundtable-e3fak28","date":1771524002,"author":"Demetrios","guid":354,"unread":true,"content":"<p>Roundtable CAST AI episode: Serving LLMs in Production: Performance, Cost &amp; Scale. </p><p>Experimenting with LLMs is easy. Running them reliably and cost-effectively in production is where things break. </p><p>Most AI teams never make it past demos and proofs of concept. A smaller group is pushing real workloads to production—and running into very real challenges around infrastructure efficiency, runaway cloud costs, and reliability at scale.</p><p>This session is for engineers and platform teams moving beyond experimentation and building AI systems that actually hold up in production.</p><p>Ioana is a Senior Product Manager at CAST AI, leading the AI Enabler product, an AI Gateway platform for cost-effective LLM infrastructure deployment. She brings 12 years of experience building B2C and B2B products reaching over 10 million users. Outside of work, she enjoys assembling puzzles and LEGOs and watching motorsports.</p><p>Igor is a founding Machine Learning Engineer at CAST AI’s AI Enabler, where he focuses on optimizing inference and training at scale. With a strong background in Natural Language Processing (NLP) and Recommender Systems, Igor has been tackling the challenges of large-scale model optimization long before transformers became mainstream. Prior to CAST AI, he worked at industry leaders like Bloomreach and Infobip, where he contributed to the development and deployment of large-scale AI and personalization systems from the early days of the field.</p><p>~~~~~~~~ ✌️Connect With Us ✌️ ~~~~~~~</p>","contentLength":1497,"flags":null,"enclosureUrl":"https://anchor.fm/s/174cb1b8/podcast/play/115740168/https%3A%2F%2Fd3ctxlq1ktw2nl.cloudfront.net%2Fstaging%2F2026-1-19%2F418421040-44100-2-e2d499a23fae4.mp3","enclosureMime":"","commentsUrl":null},{"title":"The Future of Information Retrieval: From Dense Vectors to Cognitive Search","url":"https://podcasters.spotify.com/pod/show/mlops/episodes/The-Future-of-Information-Retrieval-From-Dense-Vectors-to-Cognitive-Search-e3f7el9","date":1771351211,"author":"Demetrios","guid":353,"unread":true,"content":"<p> is a Staff Software Engineer at <a href=\"https://www.linkedin.com/\" target=\"_blank\" rel=\"ugc noopener noreferrer\">LinkedIn</a>, working on large-scale search infrastructure, information retrieval systems, and integrating AI/ML to improve ranking and semantic search experiences.</p><p>The Future of Information Retrieval: From Dense Vectors to Cognitive Search // MLOps Podcast #362 with Rahul Raja, Staff Software Engineer at LinkedIn</p><p>Information Retrieval is evolving from keyword matching to intelligent, vector-based understanding. In this talk, Rahul Raja explores how dense retrieval, vector databases, and hybrid search systems are redefining how modern AI retrieves, ranks, and reasons over information. He discusses how retrieval now powers large language models through Retrieval-Augmented Generation (RAG) and the new MLOps challenges that arise, embedding drift, continuous evaluation, and large-scale vector maintenance.</p><p>Looking ahead, the session envisions a future of Cognitive Search, where retrieval systems move beyond recall to genuine reasoning, contextual understanding, and multimodal awareness. Listeners will gain insight into how the next generation of retrieval will bridge semantics, scalability, and intelligence, powering everything from search and recommendations to generative AI.</p><p>// BioRahul is a Staff Engineer at LinkedIn, where he focuses on search and deployment systems at scale. Rahul is a graduate from Carnegie Mellon University and has a strong background in building reliable, high-performance infrastructure. He has led many initiatives to improve search relevance and streamline ML deployment workflows.</p><p>~~~~~~~~ ✌️Connect With Us ✌️ ~~~~~~~</p><p>[00:00] Vector Search for Media</p><p>[00:33] RAG and Search Evolution</p><p>[04:45] Cognitive vs Semantic Search</p><p>[08:26] High Value Search Signals</p><p>[16:43] Scaling with Embeddings</p><p>[22:37] BM25 Benchmark Bias</p><p>[29:00] Video Search Use Cases</p><p>[31:21] Context and Search Tradeoff</p><p>[35:04] Personal Memory Augmentation</p><p>[39:03] Future of Cognitive Search</p><p>[44:51] Access Control in Vectors</p><p>[49:14] Search Ranking Challenge</p><p>[54:43] Hard Search Problems Solved</p><p>[58:29] Freshness vs Cost</p>","contentLength":2047,"flags":null,"enclosureUrl":"https://anchor.fm/s/174cb1b8/podcast/play/115636329/https%3A%2F%2Fd3ctxlq1ktw2nl.cloudfront.net%2Fstaging%2F2026-1-17%2F418277708-44100-2-a7817f3055f02.mp3","enclosureMime":"","commentsUrl":null},{"title":"Rethinking Notebooks Powered by AI","url":"https://podcasters.spotify.com/pod/show/mlops/episodes/Rethinking-Notebooks-Powered-by-AI-e3f1smp","date":1771005633,"author":"Demetrios","guid":352,"unread":true,"content":"<p> is a Founding Engineer at <a href=\"https://marimo.io/\" target=\"_blank\" rel=\"ugc noopener noreferrer\">marimo</a>, working on reinventing Python notebooks as reactive, reproducible, interactive, and Git-friendly environments for data workflows and AI prototyping. He helps build the core marimo notebook platform, pushing its reactive execution model, UI interactivity, and integration with modern development and AI tooling so that notebooks behave like dependable, shareable programs and apps rather than error-prone scratchpads.</p><p>Vincent Warmerdam joins Demetrios fresh off marimo’s acquisition by Weights &amp; Biases—and makes a bold claim: notebooks as we know them are outdated.</p><p>They talk Molab (GPU-backed, cloud-hosted notebooks), LLMs that don’t just chat but actually fix your SQL and debug your code, and why most data folks are consuming tools instead of experimenting. Vincent argues we should stop treating notebooks like static scratchpads and start treating them like dynamic apps powered by AI.</p><p>It’s a conversation about rethinking workflows, reclaiming creativity, and not outsourcing your brain to the model.</p><p>Vincent is a senior data professional who worked as an engineer, researcher, team lead, and educator in the past. You might know him from tech talks with an attempt to defend common sense over hype in the data space. He is especially interested in understanding algorithmic systems so that one may prevent failure. As such, he has always had a preference to keep calm and check the dataset before flowing tonnes of tensors. He currently works at marimo, where he spends his time rethinking everything related to Python notebooks.</p><p>~~~~~~~~ ✌️Connect With Us ✌️ ~~~~~~~</p><p>[00:00] Context in Notebooks</p><p>[00:24] Acquisition and Team Continuity</p><p>[04:43] Coding Agent Conference Announcement!</p><p>[05:56] Hyperbolic GPU Cloud Ad</p><p>[06:54] marimo and W&amp;B Synergies</p><p>[09:31] marimo Cloud Code Support</p><p>[12:59] Hardest Code to Generate</p><p>[16:22] Trough of Disillusionment</p><p>[20:38] Agent Interaction in Notebooks</p>","contentLength":1933,"flags":null,"enclosureUrl":"https://anchor.fm/s/174cb1b8/podcast/play/115454105/https%3A%2F%2Fd3ctxlq1ktw2nl.cloudfront.net%2Fstaging%2F2026-1-13%2F418036639-44100-2-1cf8d7510cce7.mp3","enclosureMime":"","commentsUrl":null},{"title":"Software Engineering in the Age of Coding Agents: Testing, Evals, and Shipping Safely at Scale","url":"https://podcasters.spotify.com/pod/show/mlops/episodes/Software-Engineering-in-the-Age-of-Coding-Agents-Testing--Evals--and-Shipping-Safely-at-Scale-e3eta9q","date":1770746407,"author":"Demetrios","guid":351,"unread":true,"content":"<p> is the Founding Engineer at <a href=\"https://7ai.com/\" target=\"_blank\" rel=\"ugc noopener noreferrer\">7AI</a>, where he’s focused on building and scaling the company’s agentic AI-driven cybersecurity platform — developing autonomous AI agents that triage alerts, investigate threats, enrich security data, and enable end-to-end automated security operations so human teams can focus on higher-value strategic work.</p><p>Software Engineering in the Age of Coding Agents: Testing, Evals, and Shipping Safely at Scale // MLOps Podcast #361 with Ereli Eran, Founding Engineer at 7AI</p><p>A conversation on how AI coding agents are changing the way we build and operate production systems. We explore the practical boundaries between agentic and deterministic code, strategies for shared responsibility across models, engineering teams, and customers, and how to evaluate agent performance at scale. Topics include production quality gates, safety and cost tradeoffs, managing long-tail failures, and deployment patterns that let you ship agents with confidence.</p><p>Ereli Eran is a founding engineer at 7AI, where he builds agentic AI systems for security operations and the production infrastructure that powers them. His work spans the full stack - from designing experiment frameworks for LLM-based alert investigation to architecting secure multi-tenant systems with proper authentication boundaries. Previously, he worked in data science and software engineering roles at Stripe, VMware Carbon Black, and was an early employee of Ravelin and Normalyze.</p><p>~~~~~~~~ ✌️Connect With Us ✌️ ~~~~~~~</p><p>[00:00] Language Sensitivity in Reasoning</p><p>[00:25] Value of Claude Code</p><p>[01:54] AI in Security Workflows</p><p>[06:21] Agentic Systems Failures</p><p>[12:50] Progressive Disclosure in Voice Agents</p><p>[16:39] LLM vs Classic ML</p><p>[19:44] Hybrid Approach to Fraud</p><p>[25:58] Debugging with User Feedback</p><p>[42:07] LLM Security Workflow</p><p>[45:10] Shared Memory in Security</p><p>[49:11] Common Agent Failure Modes</p>","contentLength":1878,"flags":null,"enclosureUrl":"https://anchor.fm/s/174cb1b8/podcast/play/115304186/https%3A%2F%2Fd3ctxlq1ktw2nl.cloudfront.net%2Fstaging%2F2026-1-10%2F417834561-44100-2-32c1411bf9507.mp3","enclosureMime":"","commentsUrl":null},{"title":"Physical AI: Teaching Machines to Understand the Real World","url":"https://podcasters.spotify.com/pod/show/mlops/episodes/Physical-AI-Teaching-Machines-to-Understand-the-Real-World-e3entui","date":1770404502,"author":"Demetrios","guid":350,"unread":true,"content":"<p> is the Co-Founder and CTO at Archetype AI, working on physical AI foundation models that understand and reason over real-world sensor data.</p><p>Physical AI: Teaching Machines to Understand the Real World // MLOps Podcast #360 with Nick Gillian, Co-Founder and CTO of Archetype AI</p><p>As AI moves beyond the cloud and simulation, the next frontier is Physical AI: systems that can perceive, understand, and act within real-world environments in real time. In this conversation, Nick Gillian, Co-Founder and CTO of Archetype AI, explores what it actually takes to turn raw sensor and video data into reliable, deployable intelligence.</p><p>Drawing on his experience building Google’s Soli and Jacquard and now leading development of Newton, a foundational model for Physical AI, Nick discusses how real-time physical understanding changes what’s possible across safety monitoring, infrastructure, and human–machine interaction. He’ll share lessons learned translating advanced research into products that operate safely in dynamic environments, and why many organizations underestimate the challenges and opportunities of AI in the physical world.</p><p>Nick Gillian, Ph.D., is Co-Founder and CTO of Archetype AI with over 15 years of experience turning advanced AI and interaction research into real-world products. At Archetype, he leads the AI and engineering teams behind Newton—a first-of-its-kind Physical AI foundational model that can perceive, understand, and reason about the physical world. Before co-founding Archetype, Nick was a Senior Staff Machine Learning Engineer at Google and a researcher at MIT, where he developed AI and ML methods for real-time sensor understanding. At Google’s Advanced Technology and Projects group, he led machine learning research that powered breakthrough products like Soli radar and Jacquard, and helped advance sensing algorithms across Pixel, Nest, and wearable devices.</p><p>~~~~~~~~ ✌️Connect With Us ✌️ ~~~~~~~</p><p>Timestamps:[00:00] Physical Agent Framework[00:56] Physical AI Clarification[06:53] Building a Repair Model[12:41] World Models and LLMs[17:17] Data Weighting Strategies[24:19] Data Diversity vs Quantity[38:30] R&amp;D and Product Creation[41:22] Construction Site Data Shipping[50:33] Wrap up</p>","contentLength":2241,"flags":null,"enclosureUrl":"https://anchor.fm/s/174cb1b8/podcast/play/115127698/https%3A%2F%2Fd3ctxlq1ktw2nl.cloudfront.net%2Fstaging%2F2026-1-6%2F417599641-44100-2-b7037fd434326.mp3","enclosureMime":"","commentsUrl":null},{"title":"Speed and Scale: How Today's AI Datacenters Are Operating Through Hypergrowth","url":"https://podcasters.spotify.com/pod/show/mlops/episodes/Speed-and-Scale-How-Todays-AI-Datacenters-Are-Operating-Through-Hypergrowth-e3ej6ks","date":1770141600,"author":"Demetrios","guid":349,"unread":true,"content":"<p> is the CEO at <a href=\"https://netboxlabs.com/\" target=\"_blank\" rel=\"ugc noopener noreferrer\">NetBox Labs</a>, working on turning NetBox into the system of record and automation backbone for modern and AI-driven infrastructure.</p><p>Speed and Scale: How Today's AI Datacenters Are Operating Through Hypergrowth // MLOps Podcast #359 with Kris Beevers, CEO of NetBox Labs</p><p>Hundreds of neocloud operators and \"AI Factory\" builders have emerged to serve the insatiable demand for AI infrastructure. These teams are compressing the design, build, deploy, operate, scale cycle of their infrastructures down to months, while managing massive footprints with lean teams. How? By applying modern intent-driven infrastructure automation principles to greenfield deployments. We'll explore how these teams carry design intent through to production, and how operating and automating around consistent infrastructure data is compressing \"time to first train\".</p><p>Kris Beevers is the Co-founder and CEO of NetBox Labs. NetBox is used by nearly every Neocloud and AI datacenter to manage their networks and infrastructure. Kris is an engineer at heart and by background, and loves the leverage infrastructure innovation creates to accelerate technology and empower engineers to do their best work. A serial entrepreneur, Kris has founded and helped lead multiple other successful businesses in the internet and network infrastructure. Most recently, he co-founded and led NS1, which was acquired by IBM in 2023. He holds a Ph.D. in Computer Science from Rensselaer Polytechnic Institute and is based in New Jersey.</p><p>~~~~~~~~ ✌️Connect With Us ✌️ ~~~~~~~</p><p>[00:00] Observability and Delta Analysis</p><p>[00:26] New World Exploration</p><p>[04:06] Bottlenecks in AI Infrastructure</p><p>[13:37] Data Center Optimization Challenges</p><p>[19:58] Tech Stack Breakdown</p><p>[25:26] Data Center Design Principles</p><p>[31:32] Constraints and Automation in Design</p><p>[40:00] Complexity in Data Centers</p><p>[45:02] GPU Cloud Landscape</p><p>[50:24] Data Centers in Containers</p><p>[57:45] Observability Beyond Software</p><p>[1:04:43] Tighter Integrations vs NetBox</p>","contentLength":1983,"flags":null,"enclosureUrl":"https://anchor.fm/s/174cb1b8/podcast/play/114972764/https%3A%2F%2Fd3ctxlq1ktw2nl.cloudfront.net%2Fstaging%2F2026-1-3%2F417394904-44100-2-451b18cae6d3.mp3","enclosureMime":"","commentsUrl":null}],"tags":["podcast"]}