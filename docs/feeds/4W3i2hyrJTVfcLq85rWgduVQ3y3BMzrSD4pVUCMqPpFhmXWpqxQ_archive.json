{"id":"4W3i2hyrJTVfcLq85rWgduVQ3y3BMzrSD4pVUCMqPpFhmXWpqxQ","title":"Hacker News: Front Page","displayTitle":"HN Front","url":"https://hnrss.org/frontpage?points=75","feedLink":"https://news.ycombinator.com/","isQuery":false,"isEmpty":false,"isHidden":false,"itemCount":10,"items":[{"title":"Czech police forced to turn off facial recognition cameras at the Prague airport","url":"https://edri.org/our-work/czech-police-forced-to-turn-off-facial-recognition-cameras-at-the-prague-airport-thanks-to-the-ai-act/","date":1762022559,"author":"campuscodi","guid":218,"unread":true,"content":"<h3>Airport facial recognition system long criticised</h3><p>The Czech Republic Police used a camera system with facial recognition capabilities at Václav Havel Airport in Prague <strong>from 2018, until it was shut down in August 2025</strong>. The system enabled real-time recognition of the faces of people passing through the airport. Their so-called bio-indexes, or, simply put, facial contours converted into numbers, were compared with a database of wanted or missing persons.</p><p>EDRi member <a href=\"https://edri.org/our-work/big-brother-at-the-prague-airport-the-state-refuses-to-explain-how-the-biometric-camera-system-works/\" target=\"_blank\" rel=\"noopener\">IuRe drew attention to the situation</a> back in 2021. At the time, IuRe lawyers argued that the processing of biometric data in Czechia is only possible on the basis of explicit permission granted by a special law. IuRe ultimately filed a complaint with the Czech Data Protection Authority (DPA), requesting an investigation. The result of the inspection, which IuRe requested in the summer of 2025 under the Freedom of Information Act, <strong>confirmed the suspicion of a violation of personal data protection legislation.</strong></p><h3>Biometric surveillance ended thanks to the AI Act</h3><p>Criticism of the facial recognition system only increased after the AI Act came into force because the law explicitly requires judicial approval for each use of such a system, which wasn’t provided for the airport.</p><p>Therefore, since the specific portion of the AI Act related to biometric surveillance came into force in February 2025, till the airport facial recognition systém was shut down in August 2025, the police’s use of this system was illegal. It was in operation despite the fact that the police had been <strong>repeatedly warned of its illegality</strong> and the <a href=\"https://www.irozhlas.cz/zpravy-domov/na-prazske-letiste-se-maji-vratit-kamery-s-detekci-tvari-novelu-musi-posvetit_2506041432_dci\" target=\"_blank\" rel=\"noopener\">media had also taken an interest</a> in the matter.</p><h3>Set clear boundaries for the police</h3><p>The inspection by the Czech DPA took . During that time, no effective action was taken. However, the results are clear: police need to be given <strong>clear guidelines for processing biometric data</strong>, which should be enshrined in laws approved by elected representatives of the people and thus subject to public scrutiny. The current situation, apart from violating European legislation, creates a <strong>fertile ground for various forms of abuse of these technologies</strong>.</p><h3>The police systematically violate laws when processing biometric data</h3><p>The Czech police are also ignoring the law in the case of another biometric tool – Digital Personal Image Information System. This was also <a href=\"https://edri.org/our-work/czech-police-use-facial-recognition-system-iure-finds-out-details/\" target=\"_blank\" rel=\"noopener\">pointed out by IuRe</a> and subsequently by the Czech DPA. The system works with a reference database of <strong>approximately 20 million photographs of all persons</strong> who have been issued identity cards or passports, and compares them with photographs of persons of unknown identity.</p><p>This makes it possible to trace their probable identity retrospectively. According to the police, the system is used, for example, to identify the deceased. However, <strong>the same system can also be concievably used to identify people participating in demonstrations</strong>.</p><p>The obvious systemic problems with the use of facial recognition tools by the police should therefore be a matter of concern for the new Czech Minister of the Interior, who should initiate a <strong>review of the legislation</strong>. The current national legislation  with the European directive in terms of legal safeguards for the processing of biometric data.</p><p>IuRe will continue to monitor biometric surveillance in Czechia, thanks in part to financial support from the public received through their informational website about biometric surveillance called <a href=\"http://cnc.iure.org/\" target=\"_blank\" rel=\"noopener\">Czechia is not China</a>. The website was created with the support of EDRi and was linked to a crowdfunding campaign.</p>","contentLength":3526,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=45784185"},{"title":"Claude Code Can Debug Low-Level Cryptography","url":"https://words.filippo.io/claude-debugging/","date":1762022516,"author":"Bogdanp","guid":217,"unread":true,"content":"<p>Over the past few days I wrote a new Go implementation of ML-DSA, a post-quantum signature algorithm specified by NIST last summer. I <a href=\"https://twitch.tv/filosottile\">livecoded</a> it all over four days, finishing it on Thursday evening. Except… Verify was always rejecting valid signatures.</p><pre><code>$ bin/go test crypto/internal/fips140/mldsa\n--- FAIL: TestVector (0.00s)\n    mldsa_test.go:47: Verify: mldsa: invalid signature\n    mldsa_test.go:84: Verify: mldsa: invalid signature\n    mldsa_test.go:121: Verify: mldsa: invalid signature\nFAIL\nFAIL     crypto/internal/fips140/mldsa   2.142s\nFAIL\n</code></pre><p>I was exhausted, so I tried debugging for half an hour and then gave up, with the intention of coming back to it the next day with a fresh mind.</p><p>On a whim, I figured I would let Claude Code take a shot while I read emails and resurfaced from hyperfocus. I mostly expected it to flail in some maybe-interesting way, or rule out some issues.</p><p>Instead, it rapidly figured out a fairly complex low-level bug in my implementation of a relatively novel cryptography algorithm. I am sharing this because it made me realize I still don’t have a good intuition for when to invoke AI tools, and because I think it’s a fantastic case study for anyone who’s still skeptical about their usefulness.</p><blockquote><p>Full disclosure: Anthropic gave me a few months of Claude Max for free. They reached out one day and told me they were giving it away to some open source maintainers. Maybe it’s a ploy to get me hooked so I’ll pay for it when the free coupon expires. Maybe they hoped I’d write something like this. Maybe they are just nice. Anyway, they made no request or suggestion to write anything public about Claude Code. Now you know.</p></blockquote><p>I started Claude Code v2.0.28 with Opus 4.1 and no system prompts, and gave it the following prompt (typos included):</p><blockquote><p>I implemented ML-DSA in the Go standard library, and it all works except that verification always rejects the signatures. I know the signatures are right because they match the test vector.</p><p>YOu can run the tests with “bin/go test crypto/internal/fips140/mldsa”</p><p>You can find the code in src/crypto/internal/fips140/mldsa</p><p>Look for potential reasons the signatures don’t verify. ultrathink</p><p>I spot-checked and w1 is different from the signing one.</p></blockquote><p>Maybe I shouldn’t be surprised! Maybe it would have been clear to anyone more familiar with AI tools that this was a good AI task: a well-scoped issue with failing tests. On the other hand, this is a low-level issue in a fresh implementation of a complex,  algorithm.</p><p>It figured out that I had merged  and  into a single function for using it from Sign, and then reused it from Verify where  already produces the high bits, effectively taking the high bits of w1 twice in Verify.</p><p>Looking at <a href=\"https://gist.github.com/FiloSottile/d019f68db7143493c6a7e9c5fd08e872\">the log</a>, it loaded the implementation into the context and then  figured it out, without any exploratory tool use! After that it wrote itself a cute little test that reimplemented half of verification to confirm the hypothesis, wrote a mediocre fix, and checked the tests pass.</p><p>I <a href=\"https://go-review.googlesource.com/c/go/+/716540/2..3\">threw the fix away</a> and refactored  to take high bits as input, and changed the type of the high bits, which is both clearer and saves a round-trip through Montgomery representation. Still, this 100% saved me a bunch of debugging time.</p><h2>A second synthetic experiment</h2><p>On Monday, I had also finished implementing signing with failing tests. There were two bugs, which I fixed in the following couple evenings.</p><p>I figured these would be an interesting way to validate Claude’s ability to help find bugs in low-level cryptography code, so I checked out the old version of the change with the bugs (yay Jujutsu!) and kicked off a fresh Claude Code session with this prompt:</p><blockquote><p>I am implementing ML-DSA in the Go standard library, and I just finished implementing signing, but running the tests against a known good test vector it looks like it goes into an infinite loop, probably because it always rejects in the Fiat-Shamir with Aborts loop.</p><p>You can run the tests with “bin/go test crypto/internal/fips140/mldsa”</p><p>You can find the code in src/crypto/internal/fips140/mldsa</p><p>Figure out why it loops forever, and get the tests to pass. ultrathink</p></blockquote><p>It gave up after fixing that bug even if the tests still failed, so I started a fresh session (on the assumption that the context on the wrong constants would do more harm than good investigating an independent bug), and gave it this prompt:</p><blockquote><p>I am implementing ML-DSA in the Go standard library, and I just finished implementing signing, but running the tests against a known good test vector they don’t match.</p><p>You can run the tests with “bin/go test crypto/internal/fips140/mldsa”</p><p>You can find the code in src/crypto/internal/fips140/mldsa</p><p>Figure out what is going on. ultrathink</p></blockquote><p>It’s interesting how Claude found the “easier” bug more difficult. My guess is that maybe the large random-looking outputs of the failing tests did not play well with its attention.</p><p>The fix it proposed was updating only the allocation’s length and not its capacity, but whatever, the point is finding the bug, and I’ll usually want to throw away the fix and rewrite it myself anyway.</p><p>Three out of three one-shot debugging hits with no help is . Importantly, there is no need to trust the LLM or review its output when its job is just saving me an hour or two by telling me where the bug is, for me to reason about it and fix it.</p><p>As ever, I wish we had better tooling for using LLMs which didn’t look like chat or autocomplete or “make me a PR.” For example, how nice would it be if every time tests fail, an LLM agent was kicked off with the task of figuring out why, and only notified us if it did before we fixed it?</p><p>Enjoy the silliest floof. Surely this will help redeem me in the eyes of folks who consider AI less of a tool and more of something to be hated or loved.</p><p>My work is made possible by <a href=\"https://geomys.org\">Geomys</a>, an organization of professional Go maintainers, which is funded by <a href=\"https://smallstep.com/\">Smallstep</a>, <a href=\"https://www.avalabs.org/\">Ava Labs</a>, <a href=\"https://goteleport.com/\">Teleport</a>, <a href=\"https://tailscale.com/\">Tailscale</a>, and <a href=\"https://sentry.io/\">Sentry</a>. Through our retainer contracts they ensure the sustainability and reliability of our open source maintenance work and get a direct line to my expertise and that of the other Geomys maintainers. (Learn more in the <a href=\"https://words.filippo.io/geomys\">Geomys announcement</a>.)\nHere are a few words from some of them!</p><p>Teleport — For the past five years, attacks and compromises have been shifting from traditional malware and security breaches to identifying and compromising valid user accounts and credentials with social engineering, credential theft, or phishing. <a href=\"https://goteleport.com/platform/identity/?utm=filippo\">Teleport Identity</a> is designed to eliminate weak access patterns through access monitoring, minimize attack surface with access requests, and purge unused permissions via mandatory access reviews.</p><p>Ava Labs — We at <a href=\"https://www.avalabs.org\">Ava Labs</a>, maintainer of <a href=\"https://github.com/ava-labs/avalanchego\">AvalancheGo</a> (the most widely used client for interacting with the <a href=\"https://www.avax.network\">Avalanche Network</a>), believe the sustainable maintenance and development of open source cryptographic protocols is critical to the broad adoption of blockchain technology. We are proud to support this necessary and impactful work through our ongoing sponsorship of Filippo and his team.</p>","contentLength":7073,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=45784179"},{"title":"Visible from space, Sudan's bloodied sands expose a massacre of thousands","url":"https://www.telegraph.co.uk/world-news/2025/10/28/sudan-bloodied-sands-massacre-thousands/","date":1762019438,"author":"wslh","guid":216,"unread":true,"content":"<div data-test=\"article-body-text\"><p>Reports indicated that the RSF was deliberately forcing displaced civilians eastward into areas under its control, away from humanitarian hubs such as Tawila, where some international agencies were operating.</p><p>According to Jeremy Konyndyk, president of Refugees International, the RSF was preventing people from fleeing the town in other directions, specifically blocking movement south and west, and compelling them to move east, where there was no safety or access to aid.</p><p><a href=\"https://www.telegraph.co.uk/yvette-cooper/\">Yvette Cooper</a>, the Foreign Secretary, said: “We are witnessing a deeply disturbing pattern of abuses in El Fasher, including systematic killings, torture, and sexual violence.”</p><p>The UN Human Rights Office said it had received “multiple, alarming reports that the RSF are carrying out atrocities, including summary executions”.</p><p>Volker Türk, the UN human rights chief, said the risk of further large-scale, ethnically motivated violations and atrocities in El Fasher was “mounting by the day”.</p></div>","contentLength":973,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=45783699"},{"title":"Show HN: Why write code if the LLM can just do the thing? (web app experiment)","url":"https://github.com/samrolken/nokode","date":1762019118,"author":"samrolken","guid":204,"unread":true,"content":"<p>I spent a few hours last weekend testing whether AI can replace code by executing directly. Built a contact manager where every HTTP request goes to an LLM with three tools: database (SQLite), webResponse (HTML/JSON/JS), and updateMemory (feedback). No routes, no controllers, no business logic. The AI designs schemas on first request, generates UIs from paths alone, and evolves based on natural language feedback. It works—forms submit, data persists, APIs return JSON—but it's catastrophically slow (30-60s per request), absurdly expensive ($0.05/request), and has zero UI consistency between requests. The capability exists; performance is the problem. When inference gets 10x faster, maybe the question shifts from \"how do we generate better code?\" to \"why generate code at all?\"</p>","contentLength":789,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=45783640"},{"title":"Ask HN: Where to begin with \"modern\" Emacs?","url":"https://news.ycombinator.com/item?id=45783376","date":1762017184,"author":"weakfish","guid":215,"unread":true,"content":"Hi all,<p>I’m a longtime Neovim user who’s been EMacs-curious. The hold up for me has been that I’ve been unable to find a source of truth for what’s top-of-the-line as far as plugins are. With Neovim, it’s a safe bet to look at what folks like Folke are doing, but I have struggled to find a similar figure in the Emacs community who gives insight into what’s-what. I know Doom exists, but I want to fully “own” my config and not over complicate it.</p>","contentLength":463,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=45783376"},{"title":"Studies increasingly find links between air pollutants and dementia","url":"https://www.nytimes.com/2025/11/01/health/alzheimers-dementia-air-pollution.html","date":1762016085,"author":"quapster","guid":214,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=45783206"},{"title":"CharlotteOS – An Experimental Modern Operating System","url":"https://github.com/charlotte-os/Catten","date":1762002767,"author":"ementally","guid":210,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=45781397"},{"title":"The Smol Training Playbook: The Secrets to Building World-Class LLMs","url":"https://huggingface.co/spaces/HuggingFaceTB/smol-training-playbook","date":1761843166,"author":"kashifr","guid":207,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=45762160"},{"title":"Austria: Pylons as sculpture for public acceptance of expanding electrification","url":"https://www.goodgoodgood.co/articles/austrian-power-giants-power-line-animals","date":1761645397,"author":"Geekette","guid":206,"unread":true,"content":"<p>A concept devised by Austrian Power Grid, GP designpartners, and BauCon, these power line towers are shaped into giant animal sculptures representing nine states across the country.</p><p>There’s the stork, which represents Burgenland for its annual stork migration. And the stag, an animal symbol representing the wooded foothills of the Alps in Lower Austria.&nbsp;</p><p>These are the first two prototypes — which have already been developed and pre-tested for structural stability and high-voltage performance. But the plan is to install them across nine federal states: Burgenland, Carinthia, Lower Austria, Upper Austria, Salzburg, Styria, Tyrol, Vorarlberg, and Vienna.</p><p>“This nature-inspired design is ultimately intended to become a symbol for nature-friendly infrastructure projects, strengthen the economic and tourism location in the regions, and ultimately lead to increased acceptance of grid expansion projects by the general public,” a statement from Austrian Power Grid said.</p><p>And in the meantime, stakeholders will continue testing the feasibility of implementing these awe-inspiring animals.</p><p>“The real test will be public reception once these go live. Opposition to grid infrastructure is fierce, especially in rural and scenic areas where people (understandably) don’t want their views dominated by industrial metal,” a review from <a href=\"https://www.yankodesign.com/2025/10/22/austria-is-turning-its-power-lines-into-giant-metal-animals/\" target=\"_blank\">Yanko Design</a> shared.</p><p>“Austrian Power Grid is betting that regional pride and visual interest can shift that calculus. If a community sees a pylon as a landmark rather than an eyesore, the theory goes, acceptance follows.”</p><p><em>Header image courtesy of GP designpartners</em></p>","contentLength":1609,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=45730940"},{"title":"I built my own CityMapper","url":"https://asherfalcon.com/blog/posts/5","date":1761563933,"author":"ashfn","guid":205,"unread":true,"content":"<div><div><p>We've all used a public transit router to find a quick route from A to B, such as Google Maps or CityMapper, but how do they actually work? In this post I will discuss how I tried to build my own public transport routing system for London that supports buses, tubes and trains.</p></div></div><div><p>To limit the scope of the project, I decided to only support buses, tubes and trains in London and surrounding areas. This still, however leaves a lot of data to process, and the main goal of the project is to use live arrivals data so we know the actual time the next bus, tube or train will arrive, which needs to be updated frequently. To get an idea of the scope of these modes in London, the following table summarizes the details of each:</p></div><div><p>Anyone that's studied Graph Theory would look at a problem like this and quickly recognise that each stop/station could be a node and each journey could be an edge, and to get the fastest routes we could update the edges in real time and use Dijkstra's algorithm to find the shortest path. This would work fine in a small network, but when you have lots of edges it can take a while, and it won't optimise for the amount of transfers you take, for example it might prefer for you to take three or four buses instead of one train even if it's only a few minutes quicker, where it is obviously wildly less convenient.</p></div><div><p>The solution I decided to use is an algorithm called <a target=\"_blank\" href=\"https://www.microsoft.com/en-us/research/wp-content/uploads/2012/01/raptor_alenex.pdf\">RAPTOR</a>, which was introduced by Microsoft Research in 2012. RAPTOR optimises for the amount of transfers you take whilst minimising the time taken for the journey by running in rounds, where round  searches for routes with  transfers. It works similarly to Djikstra with how it stores the shortest time to arrive at each node, but it takes advantage of the fact that you can group the edges into the same vehicle or trip and traverse all the way to the end. You initiate the algorithm by setting the arrival time for each stop to , except the start node which you set to zero, or in my implementation I chose to use unix timestamps, so I set it to the current time in milliseconds. The algorithm will then repeat the following process for each round:</p></div><div><p>This process repeats for each round, so if you are going from A to B a direct route would be found in the first round, and then a route that might require a walk before a bus or two buses where you transfer at the exact same stop would come up in the second round. I'll now move on to one of the most difficult parts of this project, which is getting the live data. I'll start with the rail data, as it was by far the easiest to get. I got the data from the <a target=\"_blank\" href=\"https://raildata.org.uk\">Rail Data Marketplace</a>, which sounds terribly official but it's basically just a developer portal for national rail. I believe various companies sell custom data on there, but you can get all the data you need for this project for free. Creating an account was straightforward, and once I was in I found the endpoint I needed, the <a target=\"_blank\" href=\"https://raildata.org.uk/dashboard/dataProduct/P-2eec03eb-4d53-4955-8a96-0314964a4e9e/overview\">Live Arrival and Departure Boards</a>. You just supply a CRS code, which is a unique identifier for each train station, and you get a response containing the scheduled and estimated times for each train. Before I could make use of this however, I needed to know the CRS codes for all the stations and to get their coordinates which would be necessary for calculating walking times further down the line. The rail data site had an easy to use dataset for this which I hacked together a python script to parse each station and store it in a local sqlite database. Below you can see an interactive sample of the data we get in response when asking for the arrivals and departures for London Victoria:</p></div><div><code><div><div>:</div><div>:</div><div>:</div><div>:</div></div></code></div><div><p>After playing around with a few requests, I realised that the  field for each train service has two parts, for example the first train service shown above is , where the first part (the number) uniquely identifies the specific train. Using this, we can form together our unique trips to be used in the RAPTOR algorithm, and add in the time it will arrive at each stop. I couldn't find an endpoint to get this for every station, so for now the algorithm sends out requests for a few hundred stations to make sure it doesn't miss any trains, and then pieces them together.</p></div><div><p>The next part was getting the bus data. If you remember from the table before, there are thousands of buses running at a time, and the scale of the data was made apparent when I hit the TFL bus arrivals endpoint and it took over 15 seconds to load. After parsing it, I found it had over 108,000 arrival times, where each arrival time is a object with a bus stop id and a bus route, see an example of one of these objects below:</p></div><div><code><div><div><div><div>:</div><div>:</div><div>:</div><div>:</div><div>:</div><div>:</div></div></div></div></code></div><div><p>Like with the trains, we can piece together unique trips for each route using the vehicleId to group together the arrival times for the same bus, and add in the time it will arrive at each stop. The process for the London Underground was extremely similar, however you have to be careful because the vehicleId for the underground isn't unique, as each line could have multiple trains with the same vehicleId, e.g. a train on the Victoria line could have the same vehicleId as a train on the District line. To get around this, I added in the line name to the vehicleId, so now each train has a unique vehicleId like . Now I have all the trips for each mode, but something's missing - walking. Walking is crucial for two main reasons: firstly, it massively increases the number of route combinations you can take. For example, you might take a bus to a stop that's a 5-minute walk from a tube station, which could save you 20 minutes compared to staying on the bus. Secondly, it's essential for connecting stops that are technically different but practically the same - like two bus stops with identical names on opposite sides of the street, which have completely different stop IDs in the TfL system. Without walking transfers, the algorithm wouldn't even know these stops are related.</p></div><div><p>At first I considered using some public API to compute the walking times, but after doing the math I realised I could need more than a million requests, and even using servers that support batch requests could end up taking ages, but I came across an open source project called <a target=\"_blank\" href=\"https://project-osrm.org\">OSRM</a> which is a routing engine for walking, driving and cycling. I downloaded the OpenStreetMap data for England because it was the smallest available dataset that covered London, and set it up on my machine. It took around 20 minutes to load all the data and then it was ready - I could send two coordinates to the endpoint and it would immediately return the walking time between them. Between trains, tubes and buses there are over 33,500 unique stops, so for each one to limit the number of requests I only queried the walking times for stops within a few kilometers. Surprisingly, it was able to calculate over 1.8M walking distances in less than 15 minutes, and the end result was a json file that was 55MB! I'm sure I could have optimised the storage format but it wasn't large enough to be a serious issue.</p></div><div><p>To account for walking between stops, I just considered the walk from one stop to another to be a transfer and ran RAPTOR like normal. Hacking together a quick backend to allow searching for stops to pick as the start and end points and using the raptor algorithm to find the fastest route, I was able to get a working prototype. A simple frontend was then added to allow searching for routes and displaying the results. One thing I was unable to do with this project was show on the frontend the route trace for trains and tubes. For buses I could get a geoJson list of coordinates of the route the bus took and then cut it down for the stops you board and get off at, but for trains and tubes I struggled to find a reliable way of getting the route it took across the rail network, and just ended up making it draw straight lines.</p></div><div><p>I've chosen not to deploy this project publicly as I found the number of requests it has to make to stay up to date and accurate is too high for the utility it would provide, however I have recorded (and sped up) some footage of it in action below:</p></div><div><p>The code for this project is available on a git repo <a target=\"_blank\" href=\"https://github.com/ashfn/london-raptor\">here</a>, and as always thanks for reading, and feel free to reach out to me <a href=\"https://asherfalcon.com/contact\">here</a> if you have any questions or comments.</p></div>","contentLength":8253,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=45719662"}],"tags":["dev"]}