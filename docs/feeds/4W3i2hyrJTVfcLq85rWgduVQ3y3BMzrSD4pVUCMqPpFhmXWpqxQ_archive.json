{"id":"4W3i2hyrJTVfcLq85rWgduVQ3y3BMzrSD4pVUCMqPpFhmXWpqxQ","title":"Hacker News: Front Page","displayTitle":"HN Front","url":"https://hnrss.org/frontpage?points=75","feedLink":"https://news.ycombinator.com/","isQuery":false,"isEmpty":false,"isHidden":false,"itemCount":12,"items":[{"title":"AI Made Writing Code Easier. It Made Being an Engineer Harder","url":"https://www.ivanturkovic.com/2026/02/25/ai-made-writing-code-easier-engineering-harder/","date":1772374164,"author":"saikatsg","guid":195,"unread":true,"content":"<p>Yes, writing code is easier than ever.</p><p>AI assistants autocomplete your functions. Agents scaffold entire features. You can describe what you want in plain English and watch working code appear in seconds. The barrier to producing code has never been lower.</p><p>And yet, the day-to-day life of software engineers has gotten more complex, more demanding, and more exhausting than it was two years ago.</p><p>This is not a contradiction. It is the reality of what happens when an industry adopts a powerful new tool without pausing to consider the second-order effects on the people using it.</p><p>If you are a software engineer reading this and feeling like your job quietly became harder while everyone around you celebrates how easy everything is now, you are not imagining things. The job changed. The expectations changed. And nobody sent a memo.</p><h2>The Baseline Moved and Nobody Told You</h2><p>There is a phenomenon happening right now that most engineers feel but struggle to articulate. The expected output of a software engineer in 2026 is dramatically higher than it was in 2023. Not because anyone held a meeting and announced new targets. Not because your manager sat you down and explained the new rules. The baseline just moved.</p><p>It moved because AI tools made certain tasks faster. And when tasks become faster, the assumption follows immediately: you should be doing more. Not in the future. Now.</p><p>A February 2026 study published in Harvard Business Review tracked 200 employees at a U.S. tech company over eight months. The researchers found something that will sound familiar to anyone living through this shift. Workers did not use AI to finish earlier and go home. They used it to do more. They took on broader tasks, worked at a faster pace, and extended their hours, often without anyone asking them to. The researchers described a self-reinforcing cycle: AI accelerated certain tasks, which raised expectations for speed. Higher speed made workers more reliant on AI. Increased reliance widened the scope of what workers attempted. And a wider scope further expanded the quantity and density of work.</p><p>The numbers tell the rest of the story. Eighty-three percent of workers in the study said AI increased their workload. Burnout was reported by 62 percent of associates and 61 percent of entry-level workers. Among C-suite leaders? Just 38 percent. The people doing the actual work are carrying the intensity. The people setting the expectations are not feeling it the same way.</p><p>This gap matters enormously. If leadership believes AI is making everything easier while engineers are drowning in a new kind of complexity, the result is a slow erosion of trust, morale, and eventually talent.</p><p>A separate survey of over 600 engineering professionals found that nearly two-thirds of engineers experience burnout despite their organizations using AI in development. Forty-three percent said leadership was out of touch with team challenges. Over a third reported that productivity had actually decreased over the past year, even as their companies invested more in AI tooling.</p><p>The baseline moved. The expectations rose. And for many engineers, no one acknowledged that the job they signed up for had fundamentally changed.</p><h2>The Identity Crisis Nobody Talks About</h2><p>Here is something that gets lost in all the excitement about AI productivity: most software engineers became engineers because they love writing code.</p><p>Not managing code. Not reviewing code. Not supervising systems that produce code. Writing it. The act of thinking through a problem, designing a solution, and expressing it precisely in a language that makes a machine do exactly what you intended. That is what drew most of us to this profession. It is a creative act, a form of craftsmanship, and for many engineers, the most satisfying part of their day.</p><p>Now they are being told to stop.</p><p>Not explicitly, of course. Nobody walks into a standup and says ‚Äústop writing code.‚Äù But the message is there, subtle and persistent. Use AI to write it faster. Let the agent handle the implementation. Focus on higher-level tasks. Your value is not in the code you write anymore, it is in how well you direct the systems that write it for you.</p><p>For early adopters, this feels exciting. It feels like evolution. For a significant portion of working engineers, it feels like being told that the thing they spent years mastering, the skill that defines their professional identity, is suddenly less important.</p><p>One engineer captured this shift perfectly in a widely shared essay, describing how AI transformed the engineering role from builder to reviewer. Every day felt like being a judge on an assembly line that never stops. You just keep stamping those pull requests. The production volume went up. The sense of craftsmanship went down.</p><p>This is not a minor adjustment. It is a fundamental shift in professional identity. Engineers who built their careers around deep technical skill are being asked to redefine what they do and who they are, essentially overnight, without any transition period, training, or acknowledgment that something significant was lost in the process.</p><p>Having led engineering teams for over two decades, I have seen technology shifts before. New frameworks, new languages, new methodologies. Engineers adapt. They always have. But this is different because it is not asking engineers to learn a new way of doing what they do. It is asking them to stop doing the thing that made them engineers in the first place and become something else entirely.</p><p>That is not an upgrade. That is a career identity crisis. And pretending it is not happening does not make it go away.</p><h2>The Expanding Role: When Everything Becomes Your Problem</h2><p>While engineers are being asked to write less code, they are simultaneously being asked to do more of everything else.</p><p>More product thinking. More architectural decision-making. More code review. More context switching. More planning. More testing oversight. More deployment awareness. More risk assessment.</p><p>The scope of what it means to be a ‚Äúsoftware engineer‚Äù expanded dramatically in the last two years, and it happened without a pause to catch up.</p><p>This is partly a direct consequence of AI acceleration. When code gets produced faster, the bottleneck shifts. It moves from implementation to everything surrounding implementation: requirements clarity, architecture decisions, integration testing, deployment strategy, monitoring, and maintenance. These were always part of the engineering lifecycle, but they were distributed across roles. Product managers handled requirements. QA handled testing. DevOps handled deployment. Senior architects handled system design.</p><p>Now, with AI collapsing the implementation phase, organizations are quietly redistributing those responsibilities to the engineers themselves. The Harvard Business Review study documented this exact pattern. Product managers began writing code. Engineers took on product work. Researchers started doing engineering tasks. Roles that once had clear boundaries blurred as workers used AI to handle jobs that previously sat outside their remit.</p><p>The industry is openly talking about this as a positive development. Engineers should be ‚ÄúT-shaped‚Äù or ‚Äúfull-stack‚Äù in a broader sense. Nearly 45 percent of engineering roles now expect proficiency across multiple domains. AI tools augment generalists more effectively, making it easier for one person to handle multiple components of a system.</p><p>On paper, this sounds empowering. In practice, it means that a mid-level backend engineer is now expected to understand product strategy, review AI-generated frontend code they did not write, think about deployment infrastructure, consider security implications of code they cannot fully trace, and maintain a big-picture architectural awareness that used to be someone else‚Äôs job.</p><p>That is not empowerment. That is scope creep without a corresponding increase in compensation, authority, or time.</p><p>From my experience building and scaling teams in fintech and high-traffic platforms, I can tell you that role expansion without clear boundaries always leads to the same outcome: people try to do everything, nothing gets done with the depth it requires, and burnout follows. The engineers who survive are the ones who learn to say no, to prioritize ruthlessly, and to push back when the scope of their role quietly doubles without anyone acknowledging it.</p><p>There is an irony at the center of the AI-assisted engineering workflow that nobody wants to talk about: reviewing AI-generated code is often harder than writing the code yourself.</p><p>When you write code, you carry the context of every decision in your head. You know why you chose this data structure, why you handled this edge case, why you structured the module this way. The code is an expression of your thinking, and reviewing it later is straightforward because the reasoning is already stored in your memory.</p><p>When AI writes code, you inherit the output without the reasoning. You see the code, but you do not see the decisions. You do not know what tradeoffs were made, what assumptions were baked in, what edge cases were considered or ignored. You are reviewing someone else‚Äôs work, except that someone is not a colleague you can ask questions. It is a statistical model that produces plausible-looking code without any understanding of your system‚Äôs specific constraints.</p><p>A survey by Harness found that 67 percent of developers reported spending more time debugging AI-generated code, and 68 percent spent more time reviewing it than they did with human-written code. This is not a failure of the tools. It is a structural property of the workflow. Code review without shared context is inherently more demanding than reviewing code you participated in creating.</p><p>Yet the expectation from management is that AI should be making everything faster. So engineers find themselves in a bind: they are producing more code than ever, but the quality assurance burden has increased, the context-per-line-of-code has decreased, and the cognitive load of maintaining a system they only partially built is growing with every sprint.</p><p>This is the supervision paradox. The faster AI generates code, the more human attention is required to ensure that code actually works in the context of a real system with real users and real business constraints. The production bottleneck did not disappear. It moved from writing to understanding, and understanding is harder to speed up.</p><p>What makes all of this especially difficult is the self-reinforcing nature of the cycle.</p><p>AI makes certain tasks faster. Faster tasks create the perception of more available capacity. More perceived capacity leads to more work being assigned. More work leads to more AI reliance. More AI reliance leads to more code that needs review, more context that needs to be maintained, more systems that need to be understood, and more cognitive load on engineers who are already stretched thin.</p><p>The Harvard Business Review researchers described this as ‚Äúworkload creep.‚Äù Workers did not consciously decide to work harder. The expansion happened naturally, almost invisibly. Each individual step felt reasonable. In aggregate, it produced an unsustainable pace.</p><p>Before AI, there was a natural ceiling on how much you could produce in a day. That ceiling was set by thinking speed, typing speed, and the time it takes to look things up. It was frustrating sometimes, but it was also a governor. A natural speed limit that prevented you from outrunning your own ability to maintain quality.</p><p>AI removed the governor. Now the only limit is your cognitive endurance. And most people do not know their cognitive limits until they have already blown past them.</p><p>This is where many engineers find themselves right now. Shipping more code than any quarter in their career. Feeling more drained than any quarter in their career. The two facts are not unrelated.</p><p>The trap is that it looks like productivity from the outside. Metrics go up. Velocity charts look great. More features shipped. More pull requests merged. But underneath the numbers, quality is quietly eroding, technical debt is accumulating faster than it can be addressed, and the people doing the work are running on fumes.</p><h2>What Junior Engineers Are Facing</h2><p>If the picture is difficult for experienced engineers, it is even harder for those starting their careers.</p><p>Junior engineers have traditionally learned by doing the simpler, more task-oriented work. Fixing small bugs. Writing straightforward features. Implementing well-defined tickets. This hands-on work built the foundational understanding that eventually allowed them to take on more complex challenges.</p><p>AI is rapidly consuming that training ground. If an agent can handle the routine API hookup, the boilerplate module, the straightforward CRUD endpoint, what is left for a junior engineer to learn from? The expectation is shifting toward needing to contribute at a higher level almost from day one, without the gradual ramp-up that previous generations of engineers relied on.</p><p>Entry-level hiring at the 15 largest tech firms fell 25 percent from 2023 to 2024. The HackerRank 2025 Developer Skills Report confirmed that expectations are rising faster than productivity gains, and that early-career hiring remains sluggish compared to senior-level roles. Companies are prioritizing experienced talent, but the pipeline that produces experienced talent is being quietly dismantled.</p><p>This is a problem that extends beyond individual career concerns. If junior engineers do not get the opportunity to build foundational skills through hands-on work, the industry will eventually face a shortage of senior engineers who truly understand the systems they oversee. You cannot supervise what you never learned to build.</p><p>As I have written before, code is for humans to read. If the next generation of engineers never develops the fluency to read, understand, and reason about code at a deep level, no amount of AI tooling will compensate for that gap.</p><h2>What Good Leadership Looks Like Right Now</h2><p>If you lead engineering teams, the most important thing you can do right now is acknowledge that this transition is genuinely difficult. Not theoretically. Not abstractly. For the actual people on your team.</p><p>The career they signed up for changed fast. The skills they were hired for are being repositioned. The expectations they are working under shifted without a clear announcement. Acknowledging this reality is not a sign of weakness. It is a prerequisite for maintaining a team that trusts you.</p><p>Start with empathy, but do not stop there.</p><p>Give your team real training. Not a lunch-and-learn about prompt engineering. Real investment in the skills that the new engineering landscape actually requires: system design, architectural thinking, product reasoning, security awareness, and the ability to critically evaluate code they did not write. These are not trivial skills. They take time to develop, and your team needs structured support to build them.</p><p>Give them space to experiment without the pressure of immediate productivity gains. The engineers who will thrive in this environment are the ones who have room to figure out how AI fits into their workflow without being penalized for the learning curve. Every experienced technologist I know who has successfully integrated AI tools went through an adjustment period where they were less productive before they became more productive. That adjustment period is normal, and it needs to be protected.</p><p>Set explicit boundaries around role scope. If you are asking engineers to take on product thinking, planning, and risk assessment in addition to their technical work, name it. Define it. Compensate for it. Do not let it happen silently and then wonder why your team is burned out.</p><p>Rethink your metrics. If your engineering success metrics are still centered on velocity, tickets closed, and lines of code, you are measuring the wrong things in an AI-assisted world. System stability, code quality, decision quality, customer outcomes, and team health are better indicators of whether your engineering organization is actually producing value or just producing volume.</p><p>Protect the junior pipeline. If you have stopped hiring junior engineers because AI can handle entry-level tasks, you are solving a short-term efficiency problem by creating a long-term talent crisis. The senior engineers you rely on today were junior engineers who learned by doing the work that AI is now consuming. That path still matters.</p><p>And finally, keep challenging your team. I have never met a good engineer who did not love a good challenge. The engineers on your team are not fragile. They are capable, intelligent people who signed up for hard problems. They can handle this transition. Just make sure they are set up to meet it.</p><h2>What Engineers Can Do for Themselves</h2><p>If you are an engineer navigating this shift, here is what I would tell you based on two decades of watching technology cycles reshape this profession.</p><p>First, do not abandon your fundamentals. The pressure to become an ‚ÄúAI-first‚Äù engineer is real, but the engineers who will be most valuable in five years are the ones who deeply understand the systems they work on. AI is a tool. Understanding architecture, debugging complex systems, reasoning about performance and security: these skills are not becoming less important. They are becoming more important because someone needs to be the adult in the room when AI-generated code breaks in production at 2 AM.</p><p>Second, learn to set boundaries with the acceleration trap. Just because you can produce more does not mean you should. Sustainable pace matters. The engineers who burn out trying to match the theoretical maximum output AI makes possible are not the ones who build lasting careers. The ones who learn to work with AI deliberately, choosing when to use it and when to think independently, are the ones who will still be thriving in this profession a decade from now.</p><p>Third, embrace the parts of the expanded role that genuinely interest you. If the engineering role now includes more product thinking, more architectural decision-making, more cross-functional communication, treat that as an opportunity rather than an imposition. These are skills that senior engineers and technical leaders need. You are being given access to a broader set of capabilities earlier in your career than any previous generation of engineers. That is not a burden. It is a head start.</p><p>Fourth, talk about what you are experiencing. The isolation of feeling like you are the only one struggling with this transition is one of the most damaging aspects of the current moment. You are not the only one. The data confirms it. Two-thirds of engineers report burnout. The expectation gap between leadership and engineering teams is well documented. Talking openly about these challenges, with your team, with your manager, with your broader network, is not complaining. It is professional honesty.</p><p>And fifth, remember that this profession has survived every prediction of its demise. COBOL was supposed to eliminate programmers. Expert systems were supposed to replace them. Fourth-generation languages, CASE tools, visual programming, no-code platforms, outsourcing. Every decade brings a new technology that promises to make software engineers obsolete, and every decade the demand for skilled engineers grows. AI will not be different. The tools change. The fundamentals endure.</p><h2>The Paradox We Need to Name</h2><p>AI made writing code easier and made being an engineer harder. Both of these things are true at the same time, and pretending that only the first one matters is how organizations lose their best people.</p><p>The engineers who are struggling right now are not struggling because they are bad at their jobs. They are struggling because their jobs changed underneath them while the industry celebrated the part that got easier and ignored the parts that got harder.</p><p>Expectations rose without announcement. Roles expanded without boundaries. Output demands increased without corresponding increases in support, training, or acknowledgment. And the engineers who raised concerns were told, implicitly or explicitly, that they just needed to adapt faster.</p><p>That is not how you build a sustainable engineering culture. That is how you build a burnout machine.</p><p>The industry needs to name this paradox honestly. AI is an incredible tool. It is also placing enormous new demands on the people using it. Both things can be true. Both things need to be addressed.</p><p>The organizations that get this right, that invest in their people alongside their tools, that acknowledge the human cost of rapid technological change while still pushing forward, those are the organizations that will attract and retain the best engineering talent in the years ahead.</p><p>The ones that do not will discover something that every technology cycle eventually teaches: tools do not build products. People do. And people have limits that no amount of AI can automate away.</p><p><em>If this resonated with you, I would love to hear your perspective. What has changed most about your engineering role in the last year? Drop me a message or connect with me on <a href=\"https://www.linkedin.com/in/ivanturkovic/\">LinkedIn</a>. I write regularly about the intersection of AI, software engineering, and leadership at <a href=\"https://ivanturkovic.com\">ivanturkovic.com</a>. Follow along if you want honest, experience-driven perspectives on how technology is actually changing this profession.</em></p>","contentLength":21396,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47206824"},{"title":"Ape Coding","url":"https://rsaksida.com/blog/ape-coding/","date":1772374025,"author":"rmsaksida","guid":194,"unread":true,"content":"<p> is a software development practice where a human developer deliberately hand-writes source code. Practitioners of ape coding will typically author code by typing it on a computer keyboard, using specifically designed text editing software.</p><p>The term was popularized when  (coding performed by AI agents) became the dominant form of software development. Ape coding first appeared in programming communities as derogatory slang, referring to developers who were unable to program with agents. Despite the quick spread of agentic coding, institutional inertia, affordability, and limitations in human neuroplasticity were barriers to universal adoption of the new technology.</p><p>Critics of agentic coding reappropriated the term during a period of pushback against society‚Äôs growing reliance on AI. Effective use of the primitive AIs available at the time demanded a high level of expertise, which wasn‚Äôt evenly distributed in organizations. As a result, regressions in software products and disruptions in electronic services were frequent within the first stages of adoption.</p><p>Ironic usage of ape coding as a positive description became commonplace. It highlighted a more deliberate approach to building software: one defined by manual craftsmanship, requiring direct and continuous human involvement.</p><p>The central view of ape coding proponents was that software engineered by AIs did not match the reliability of software engineered by humans, and should not be deployed to production environments.</p><p>A recurring argument in favor of this perspective was based on comprehensibility. The volume of code AI developers could produce on demand was much larger than what human developers were able to produce and understand in a similar timeframe. Large and intricate codebases that would take an experienced human engineer months or years to grasp could be produced in hours. The escalating complexity of such codebases hindered efforts in software testing and quality assurance.</p><p>AI skepticism also played a part in the critique of agentic coding. There was widespread speculation on whether the nascent AIs of the period possessed true understanding of the tasks they were given. Furthermore, early AI implementations had deficiencies related to context length, memory, and continual learning, affecting quality and consistency of output.</p><p>Other defenses of ape coding reflected concerns about the impact of AI on labor markets. Despite the shortcomings of AI-written software, human developers were increasingly replaced by agents, with examples of high profile companies laying off large portions of their IT staff.</p><p>Tangentially, the responsibilities of human software engineers shifted when an essential aspect of their work (coding) was automated. The activities that remained were more similar to management, QA, and in some cases assistant roles. A common observation was that the human engineers who were still employed no longer enjoyed their line of work.</p><h3>Advocacy for human-written software</h3><p>Ape coding advocates argued that a return to human-written software would resolve the issues introduced by AI software development. Interest groups campaigned for restrictions on agentic coding, subsidies for AI-free software companies, quotas for human developers, and other initiatives in the same vein.</p><p>Although ape coding advocacy enjoyed a brief moment of popular support, none of these objectives were ever achieved.</p><p>Advances in AI quickly turned ape coding into an antiquated practice. Technical arguments for ape coding did not apply to newer generations of AI software engineers, and political arguments were seen as a form of neo-Luddism. Once virtually all software engineering was handed over to AIs, the concept of ape coding fell into obscurity.</p><h2>Revival and modern practice</h2><p>A resurgence of interest in ape coding has revived the practice among human hobbyists. Communities and subcommunities have formed where ape coders‚Äîas they came to be known‚Äîdiscuss computer science topics, including programming languages and software engineering.</p><p>Prominent ape coding clubs have attracted hundreds of thousands of members who exchange ideas and human-written programs. The clubs organize in-person as well as virtual gatherings where teams of ape coders collaborate on software projects.</p><p>The main value of modern ape coding appears to be recreational. Ape coders manifest high levels of engagement during coding sessions and report feelings of relaxation after succeeding in (self-imposed) coding challenges. Competitive ape coding is also popular, with top ranked ape coders being relatively well-known in their communities.</p><p>Aside from recreation, humans pursue ape coding for its educational value. Many have described ape coding as a way to gain a deeper understanding of the world around them. While an interest in ape coding was initially perceived as an unusual quirk, it is currently seen as a positive trait in human society, signaling curiosity.</p><p>Members of the software archaeology community published a series of articles on the human-written Linux kernel that had a deep impact in the larger ape coding world.</p><p>Considered by ape coders to be the ultimate work of human software engineers (in scale, complexity, and longevity), Linux inspired a wave of initiatives to build large scale software projects featuring thousands of human collaborators.</p><p>The most promising of these efforts is based on studies by the AI-written software interpretability community. The goal is to produce an entirely human-written compiler for the AI-designed programming language íÄØ. A fully compliant implementation is estimated to be many times as complex as the Linux kernel, but a prototype with limited scope is within human capabilities and is currently the primary focus of enthusiasts.</p><p>Results so far have been encouraging, as the latest version of h-íÄØ is able to build functional binaries for small programs. However, the initiative has recently suffered a setback as core contributors to its codebase left to work on a fork. The split was motivated by heated debates on whether C is the most suitable programming language for the project; dissenters expressed a desire to rewrite it in Rust.</p>","contentLength":6175,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47206798"},{"title":"Ghostty ‚Äì Terminal Emulator","url":"https://ghostty.org/docs","date":1772367183,"author":"oli5679","guid":193,"unread":true,"content":"<p>Ghostty is a fast, feature-rich, and cross-platform terminal emulator\nthat uses platform-native UI and GPU acceleration.</p>","contentLength":120,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47206009"},{"title":"I built a demo of what AI chat will look like when it's \"free\" and ad-supported","url":"https://99helpers.com/tools/ad-supported-chat","date":1772365741,"author":"nickk81","guid":192,"unread":true,"content":"<div>üì∫ Advertisement ‚Äî Before Your Free Chat</div><p>The #1 AI Productivity App of 2025!</p><p>Join  who think faster, focus better, and accomplish more. AI-powered goal tracking, habit building, and memory enhancement.</p>","contentLength":203,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47205890"},{"title":"Why is the first C++ (m)allocation always 72 KB?","url":"https://joelsiks.com/posts/cpp-emergency-pool-72kb-allocation/","date":1772357254,"author":"joelsiks","guid":191,"unread":true,"content":"<p>: I updated the title to to clarify that this observation is specific to my environment. The original title may have implied a universal behavior, which isn‚Äôt the case. Thanks for the feedback!</p><p>; The C++ standard library sets up exception handling infrastructure early on, allocating memory for an ‚Äúemergency pool‚Äù to be able to allocate memory for exceptions in case malloc ever runs out of memory.</p><p>I like to spend (some of) my time hacking and experimenting on custom memory allocators with my own malloc implementation(s). While unit tests are useful for correctness, the ultimate test is seeing how the allocator behaves in real-world programs. On Linux, overriding the default malloc is surprisingly simple: wrap the standard allocation functions (e.g., malloc, calloc, realloc, free, and utilities like malloc_usable_size), compile your implementation into a shared library, and use  to force programs to load it first. For example, you can test your allocator with a simple command like this:</p><div><pre tabindex=\"0\"><code data-lang=\"bash\"></code></pre></div><p>To better understand how programs allocate memory, I built a debug tool that logs the size of every allocation request to a file. You have to be careful when creating debug tools like this when implementing malloc to not internally use malloc to log output. Otherwise, you risk an infinite loop and a crash. To solve this I‚Äôm using a stack-allocated buffer together with low-level functions like creat, write and snprintf to safely capture the data.</p><div><pre tabindex=\"0\"><code data-lang=\"bash\"></code></pre></div><p>While analyzing allocation patterns across different programs, I noticed something unusual: the very first allocation is always 73728 bytes (72 KB). Every program I tested exhibited this behavior, as confirmed by my debug logs:</p><p>To track down the first call to malloc, I use gdb to set a breakpoint into my own malloc function to inspect the backtrace.</p><p>: Setting a breakpoint on the ‚Äúmalloc‚Äù symbol will not only trigger for our own malloc, but also the dynamic linker‚Äôs (RTLD) internal malloc, so we have to be more specific. RTLD uses its own minimal malloc implementation for early memory allocation, before libc (or our own malloc) is loaded. I encourage you to take a look at glibc‚Äôs <a href=\"https://elixir.bootlin.com/glibc/glibc-2.43.9000/source/elf/dl-minimal-malloc.c\">elf/dl-minimal-malloc.c</a>, it is remarkably approachable.</p><div><pre tabindex=\"0\"><code data-lang=\"bash\"></code></pre></div><p>The backtrace revealed that the first 72 KB allocation originated from libstdc++. While adding debug symbols helps narrow it down a bit, it‚Äôs hard to pinpoint the exact function responsible for the malloc call due to inlining. All we know is that the malloc call comes from something down the line from <code>__pool_alloc_base::_M_allocate_chunk</code>.</p><div><pre tabindex=\"0\"><code data-lang=\"bash\"></code></pre></div><p>Identifying the exact caller took some time, but I narrowed it down by cross-referencing known functions in the assembly code with the libstdc++ source code. The investigation led me to <a href=\"https://github.com/gcc-mirror/gcc/blob/8758503918a91dacff4dbc7126eced21787fbfc9/libstdc%2B%2B-v3/libsupc%2B%2B/eh_alloc.cc#L235\">libstdc++-v3/libsupc++/eh_alloc.cc</a>, where ‚Äúeh‚Äù stands for ‚Äúexception handling‚Äù. This made sense because  is likely the first point where an exception could be thrown, so the exception-handling infrastructure must be initialized, which is presumably done lazily.</p><div><pre tabindex=\"0\"><code data-lang=\"c++\"></code></pre></div><h2>Exception Handling Infrastructure (Emergency Pool)</h2><p>The 72 KB call to malloc we‚Äôre seeing is memory for the so called ‚Äúemergency pool‚Äù, which is allocated in the constructor of the pool:</p><div><pre tabindex=\"0\"><code data-lang=\"c++\"></code></pre></div><p>Normally, exceptions are allocated directly via malloc, but if the malloc call fails, the exception is allocated from the emergency pool instead. This ensures that exceptions can still be thrown (to the extent of the size of the emergency pool) even when malloc fails, providing a last line of defense for error handling. The emergency pool is allocated lazily at program startup, since memory is more likely to be available then, which explains why we see this allocation so consistently.</p><div><pre tabindex=\"0\"><code data-lang=\"c++\"></code></pre></div><h2>Emergency Pool Sizing. Why 72 KB?</h2><p>Looking in the source file there is a brief explanation of how the size of the emergency pool is calculated. Both the object size and the number of objects are based on the wordsize, so 8 bytes on a 64-bit system.</p><div><pre tabindex=\"0\"><code data-lang=\"c++\"></code></pre></div><p>The object size (obj_size) and number of objects (obj_count) can be tuned manually via the  environment variable. We can empirically verify that the initial allocation is actually for the emergency pool by changing the number of objects in the pool. As expected, we see the initial allocation size go down when we change the number of objects:</p><div><pre tabindex=\"0\"><code data-lang=\"bash\"></code></pre></div><p>As a side note, the emergency pool can also be disabled (i.e., not allocated), by setting the number of objects to 0. Alternatively, you can opt-in to use a fixed-size static buffer for the emergency pool by configuring <code>--enable-libstdcxx-static-eh-pool</code> when building libstdc++.</p><div><pre tabindex=\"0\"><code data-lang=\"txt\"></code></pre></div><p>However, in older Valgrind versions, this memory appeared as ‚Äústill reachable‚Äù rather than properly freed. While ‚Äústill reachable‚Äù memory isn‚Äôt technically a leak (the program still has references to it), it can be misleading. See post on <a href=\"https://stackoverflow.com/questions/45537965/how-does-a-c-library-implementation-allocate-memory-but-not-free-it-when-the-p\">Stack Overflow</a> detailing this behavior. Interestingly, this person sees a 71 KB allocation instead of 72 KB.</p><div><pre tabindex=\"0\"><code data-lang=\"txt\"></code></pre></div><p>Many developers mistakenly interpret this behavior as a memory leak, leading to unnecessary confusion. To address this, newer Valgrind versions now explicitly free the emergency pool during cleanup, providing clearer reports. This is implemented through the mechanisms shown below, which were added specifically for tools like Valgrind:</p><div><pre tabindex=\"0\"><code data-lang=\"c++\"></code></pre></div><div><pre tabindex=\"0\"><code data-lang=\"c++\"></code></pre></div><p>The memory allocated for the emergency pool explains why I‚Äôve been able to consistently observe a 72 KB allocation when testing my custom allocator. Since I‚Äôve implemented my custom allocator in C++, it inherently depends on libstdc++, which initializes the emergency pool on every program invocation. Interestingly, if I had written my allocator in C instead, which several popular malloc implementations are implemented in (<a href=\"https://github.com/microsoft/mimalloc\">mimalloc</a>, <a href=\"https://github.com/jemalloc/jemalloc\">jemalloc</a>), I would only see this initial allocation when testing C++ binaries, which explicitly link against libstdc++.</p><p>You might see a different allocation size (e.g., 71 KB instead of 72 KB), or no allocation at all. Factors like different versions of libstdc++, using libc++ instead, or even compiler flags can introduce variations. Still, in most cases, you‚Äôll likely see memory for the emergency pool allocated early, perhaps with different sizes or behaviors depending on the environment.</p><p>As you quickly find out when working with memory allocation is that almost everything needs to allocate memory. From time immemorial with RTLD needing its own malloc since it hasn‚Äôt loaded libc yet, or for the emergency pool, which only uses malloc to allocate memory for its own pool allocator!</p><p>Digging through the code and piecing this together was rewarding and fun. I hope you enjoyed the journey as much as I did!</p>","contentLength":6593,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47205129"},{"title":"Decision trees ‚Äì the unreasonable power of nested decision rules","url":"https://mlu-explain.github.io/decision-tree/","date":1772355352,"author":"mschnell","guid":190,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47204964"},{"title":"10-202: Introduction to Modern AI (CMU)","url":"https://modernaicourse.org/","date":1772350503,"author":"vismit2000","guid":188,"unread":true,"content":"<ul><li> MW[F] 9:30‚Äì10:50 Tepper 1403 (note: Friday lectures will only be used for review sessions or makeup lectures when needed)</li></ul>\n    A minimal free version of this course will be offered online, simultaneous to the CMU offering, starting on 1/26 (with a two-week delay from the CMU course).  This means that  (lecture videos, assignments available on mugrade, etc) will be available to the online course  after the dates indicated in the schedule below.  By this, we mean that anyone will be able to watch lecture videos for the course, and submit (autograded) assignments (though not quizzes or midterms/final).  <a href=\"https://modernaicourse.org/enroll.html\">Enroll here</a> to receive emails on lectures and homeworks once they are available.  Note that information here about TAs, office hours, grading, prerequisites, etc, are for the CMU version, not the online offering.\n\n  <p>\n    This course provides an introduction to how modern AI systems work. By ‚Äúmodern AI‚Äù, we specifically mean the machine learning methods and large language models (LLMs) behind systems like ChatGPT, Gemini, and Claude.\n    <a href=\"https://modernaicourse.org/#\" onclick=\"toggleFootnote('fn1-box', this); return false;\">[Note]</a>\n    Despite their seemingly amazing generality, the basic techniques that underlie these AI models are surprisingly simple: a minimal LLM implementation leverages a fairly small set of machine learning methods and architectures, and can be written in a few hundred lines of code.\n  </p><p>\n    This course will guide you through the basic methods that will let you implement a basic AI chatbot. You will learn the basics of supervised machine learning, large language models, and post-training. By the end of the course you will be able to write the code that runs an open source LLM from scratch, as well as train these models based upon a corpus of data. The material we cover will include:\n  </p><ul><li>Supervised machine learning\n      <ul><li>Loss functions and optimization</li></ul></li><li>Large language models\n      <ul><li>Self attention and transformers</li></ul></li><li>Post-training\n      <ul><li>Alignment and instruction tuning</li><li>Reasoning models and reinforcement learning</li><li>Safety and security of AI systems</li></ul></li></ul><p>\n    The topics above are a general framing of what the course will cover. However, as this course is being offered for the first time in Spring 2026, some elements are likely to change over the first offering.\n  </p><ul><li>20% - Homework and Programming Assignments</li><li>40% - Midterms and Final (10% each midterm, 20% final)</li></ul><ul><li> 15-112 or 15-122. You must be proficient in basic Python programming, including object oriented methods.</li><li> 21-111 or 21-120. The course will use basic methods from differential calculus, including computing derivatives. Some familiarity with linear algebra and probability is also beneficial, but these topics will be covered to the extent needed for the course.</li></ul><h2>Homework and Programming Assignments</h2><p>\n    A major component of the course will be the development of a minimal AI chatbot through a series of programming assignments.  Homeworks are submitted using <a href=\"https://mugrade.org\">mugrade</a> system (<a href=\"https://youtu.be/jrtb9y6xg6U\">tutorial video</a>). Some assignments build on previous ones, though for the in-class CMu version we'll distribute solutions to help you work through any errors that may have cropped up in previous assignments (for the online version, we'd suggest talking to others who were able to complete the assignment). In addition to the (main) programming aspect, some homeworks may contain  shorter written portion that works out some of the mathematical details behind the approach.\n  </p><p>\n    All homeworks are released as Colab notebooks, at the links below.  We are also releasing <a href=\"https://marimo.io/\">Marimo</a> notebook versions.  The mugrade version of the online assignment will be available two weeks after the release dates for the CMU course.\n  </p><p>\n    Each homework will be accompanied by an in-class (15 minute) quiz that assesses basic questions based upon the assignment. This will include replicating (at a high level) some of the code you wrote for the assignment, or answering conceptual questions about the assignment. All quizzes are closed book and closed notes.\n  </p><p>\n    In addition to the homework quizzes, there will be 3 in-person exams, two midterms and a final (during finals period). The midterms will focus on material only covered during that section of the courses, while the final will be cumulative (but with an emphasis on the last third of the course). All midterms and final and closed book and closed notes.\n  </p><p>\n    Lecture schedule is tentative and will be updated over the course of semester.  All materials will be available to the online course two weeks after the dates here.\n  </p><table border=\"0\" cellspacing=\"0\" cellpadding=\"4\"><tbody><tr></tr><tr><td>Intro to supervised learning (<a href=\"https://youtu.be/xIQkf7ZGQhM\">video</a>) </td></tr><tr><td>Linear algebra and PyTorch (<a href=\"https://youtu.be/tlbLH77GFLQ\">video</a>) </td></tr><tr></tr><tr><td>Loss functions and probability (<a href=\"https://youtu.be/v3-kn7ErcE4\">video</a>) </td></tr><tr><td>Optimization and gradient descent (<a href=\"https://youtu.be/zKSghsymDdc\">video</a>) </td></tr><tr><td>Putting it together: Training a linear model (<a href=\"https://youtu.be/DaZFJ1tKbAQ\">video</a>)/td&gt;</td></tr><tr><td>Neural networks models (<a href=\"https://youtu.be/9ukf-DPcqcQ\">video</a>) </td></tr><tr><td>Neural network implementation</td></tr><tr><td><strong>Midterm 1 - Supervised machine learning</strong></td></tr><tr><td>Sequence models: handling sets of inputs</td></tr><tr><td>Self attention and positional embeddings</td></tr><tr></tr><tr></tr><tr></tr><tr><td>Efficient inference and key-value caching</td></tr><tr><td>Putting it together: your first LLM</td></tr><tr><td><strong>Midterm 2 - Large Language Models</strong></td></tr><tr></tr><tr><td>Alignment and instruction/chat tuning</td></tr><tr></tr><tr><td>Reinforcement learning basics</td></tr><tr></tr><tr></tr><tr><td>The future: AGI and beyond</td></tr></tbody></table><h2>AI Policy for the AI course</h2><p>\n    Students are permitted to use AI assistants for all homework and programming assignments (especially as a reference for understanding any topics that seem confusing), but we strongly encourage you to complete your final submitted version of your assignment without AI. You cannot use any such assistants, or any external materials, during in-class evaluations (both the homework quizzes and the midterms and final).\n  </p><p>\n    The rationale behind this policy is a simple one: AI can be extremely helpful as a learning tool (and to be clear, as an actual implementation tool), but over-reliance on these systems can currently be a detriment to learning in many cases. You  need to learn how to code and do other tasks using AI tools, but turning in AI-generated solutions for the relatively short assignments we give you can (at least in our current experience) ultimately lead to substantially less understanding of the material. The choice is yours on assignments, but we believe that you will ultimately perform much better on the in-class quizzes and exams if you do work through your final submitted homework solutions yourself.\n  </p>","contentLength":6211,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47204559"},{"title":"An ode to houseplant programming (2025)","url":"https://hannahilea.com/blog/houseplant-programming/","date":1772205550,"author":"evakhoury","guid":182,"unread":true,"content":"<p><a target=\"_blank\" rel=\"noreferrer noopener\" href=\"https://www.recurse.com/\">Recurse Center (RC)</a> peer <a target=\"_blank\" rel=\"noreferrer noopener\" href=\"https://rygoldstein.com\">Ryan</a> recently coined a phrase that I instantly\n        fell in love with: .\n      </p><blockquote><p>\n          [The tool I built] solves my idiosyncratic problems and may not address yours at all. That‚Äôs fine‚Äîtake it as an ad to write tiny software just for yourself. Houseplant programming ü™¥ !  This isn‚Äôt an existing phrase as far as I know, but the closest I can think of is ‚Äúbarefoot developers‚Äù which a) is a little more granola than my vibe and b) is maybe tied up in some AI stuff. I guess this is\n          <a target=\"_blank\" rel=\"noreferrer noopener\" href=\"https://gwern.net/doc/technology/2004-03-30-shirky-situatedsoftware.html\">situated software</a> but even smaller: I‚Äôm not building for dozens of users, I‚Äôm building for one user\n          in particular.</p></blockquote><p>Houseplant programming: tiny software just for yourself. </p><p>At the risk of overexplaining and thus cheapening the analogy, I feel the need to wax poetic.ü™¥</p><h2>When ‚ÄúIt works on my machine‚Äù is the goal, not the excuse</h2><p>Things I have found myself saying about some personal projects, almost apologetically:</p><p>\n        In the world of houseplant programming none of these statements are apology-worthy. In a workplace, about a project that is intended for\n        productionization and mass dissemination? Sure, production-ready code‚Äîcode that has a job, or provides the infrastructure for a job‚Äîneeds to be some\n        flavor of robust and tested and reliable. For a project that lives in my house and does what I need it to and periodically needs a little extra help? No worries.\n      </p><p><a target=\"_blank\" rel=\"noreferrer noopener\" href=\"https://www.evalapply.org/\">Aditya Athalye</a> (another RC peer!) perfectly captures this vibe in the project description for his software project\n        <a target=\"_blank\" rel=\"noreferrer noopener\" href=\"https://github.com/adityaathalye/shite?tab=readme-ov-file\"></a>:\n      </p><blockquote><p>‚Äôs job is to help me make my website: <a target=\"_blank\" rel=\"noreferrer noopener\" href=\"https://evalapply.org\">https://evalapply.org</a>. Thus, ‚Äôs scope, (mis)feature set, polish will always be\n          production-grade, where production is ‚Äúworks on my machine(s)‚Äù :) </p></blockquote><p>Strong ‚ÄúEverything I do is the attitude of an award winner because I have won an award‚Äù energy:</p><p>Any code is production ready, if you redefine the scope of your production environment!</p><h2>Properties of houseplants, programmatic and chlorophyllous</h2><p>\n        Before we get to the self-reflective bit, here is a non-exhaustive list of parallels between my houseplants and my houseplant programs:\n      </p><ul><li>: I love having both plants and homemade projects in my living space. Sharing a space with them reminds me of things that I like about the world and about myself.</li></ul><ul><li>: Like my plants, I love my little projects and I want them to thrive, and I baby them a little bit to get them started. But also, if they don‚Äôt work out? It isn‚Äôt a big deal, into\n           Github they go, where a hard-won line or two may be  recycled into a future project.\n        </li></ul><ul><li><p>: Clippings! I love to propagate my plants and share them with friends. Do you want a pilea or a spider plant or a nice philodendron? Let me know, I‚Äôll hook you up! Similarly, do you want to set up\n            <a href=\"https://hannahilea.com/blog/ly-drawbot-setup/\">your own pen plotter</a> or make some quick and easy <a href=\"https://hannahilea.com/blog/meme-making/\">screenshot memes</a>? Awesome, I try to document and share the code and steps for recreating most of my projects.\n          </p><p>\n            That said, once a plant/code has taken up residence in your home, it is no longer my responsibility. While I‚Äôd love to hear about what you did to help it thrive, and if it starts looking sad I‚Äôll gladly help you think through\n            what might help, if it never thrives I‚Äôm probably not going to lose sleep over it.\n          </p><p>Besides, once you‚Äôve gotten as far as propagating the code/plant I‚Äôve given you, you‚Äôll know about as much about the situation as I do‚Äîmaybe more‚Äîand now we can explore the next steps together.</p></li><li><p>: Just like some plants, <a href=\"https://hannahilea.com/blog/clapping-music-for-flip-disc-displays/\">some projects</a> are practically poisonous to my cat and‚Äîif the cat had her way‚Äîshould be rehomed with a pet-free pal.\n          </p></li></ul><ul><li><p>: I don‚Äôt care to engineer my houseplants to thrive in every environment‚Äîand similarly, I don‚Äôt feel a need to make my houseplant code fully generalizable, until there is a more specific reason\n            to do so.\n          </p></li><li><p>: I love reading about other people‚Äôs houseplant projects. While I occasionally take code cuttings for my own home, mostly I just want to wander around and admire their houseplants and learn\n            more about the woes they encountered when figuring out how to help their code/plants thrive.\n          </p><p>I do not need to propagate someone‚Äôs houseplant [code] in my own home in order to admire it; I can learn to consider a different fertilizer or communication protocol without transplanting their program into my own home.</p></li><li><p>: One person‚Äôs houseplants are another person‚Äôs plant nursery. One person‚Äôs houseplant code is another person‚Äôs B2B SaaS product. Enough said.</p></li><li><p>: Soil gnats. Where do they even come from?! It is unknowable.</p><p>\n            Sometimes my weather station shows me the icon for snow, even though it is currently April and the temperature isn‚Äôt predicted to dip below 32. ¬Ø\\_(„ÉÑ)_/¬Ø\n            </p></li></ul><ul><li>: It is really, really fun to grow plants. It is really really fun to write code.</li></ul><h2>Not an idea, not yet a Platonic ideal</h2><p>\n        While I build software as a career, I also like to muck about with code in service of other goals. When sharing those other projects it has taken me a long time be able to talk about what my code does do without adding a zillion\n        caveats about what the code  do.</p><p>\n        Why? I think somewhere along the line I picked up the unhealthy‚Äîand false!‚Äîassumption that it wasn‚Äôt worth sharing my code until it was ready to be reused easily by whoever was able to access it‚Äîspecifically, not sharing that code\n        until it was ‚Äúproduction ready,‚Äù for some arbitrary and ever-growing definition of ‚Äúproduction‚Äù that I never  fully defined for myself.</p><p>\n        In the last year or so when presenting personal projects I‚Äôve taken to saying that they‚Äôre prototypes. Prototyping is a thing that makes sense to many folks in the field‚Äîit involves a first pass at trying to build something, with\n        output that  be optimized, might be hacked together with glue and dreams, and possibly even ‚Äúonly works on my machine‚Äù. But it‚Äôs proof that it is worth spending more time on something, or  worth spending\n        more time on something.</p><p>\n        The thing is, a lot of the personal projects I‚Äôve built are  prototypes, even if they share a lot of the same characteristics of a prototype: while they are a first-ish pass at bringing an idea to life, and they\n         be turned into a more generalizable or generic Thing, they‚Äôre never designed to be more than that first pass with its context-specific configuration.\n      </p><p>\n        While rebranding some of the projects I‚Äôve built as ‚Äúprototypes‚Äù helped me feel better about sharing something not totally polished, I‚Äôve also felt like the term somehow devalues what I‚Äôve built. Sure, sometimes what I‚Äôve built\n         a prototype! But often, it isn‚Äôt. It‚Äôs a first pass, sure, but it‚Äôs just a <a target=\"_blank\" rel=\"noreferrer noopener\" href=\"https://www.patreon.com/posts/make-little-guys-112268885\">weird little guy</a> of an idea, and\n        doesn‚Äôt need to promise to be any more than what it already is. Just existing is enough,and I‚Äôm not necessarily interested in developing it into a less-weird less-little guy!\n      </p><p>Thus: houseplant programming. Tiny software for just myself.</p><h2>Epilogue: Bouquet programming üíê</h2><p>I‚Äôm going to spare us all a further brainstorm of plant/code parallels, with the exception of one spin-off term:  üíê.</p><p>\n        I‚Äôm hereby defining bouquet programming as one-off code that is written for one specific user <em>to support one specific use-case</em>, in a non-recurring way. By definition, it needs no maintenance and simply provides proof of\n        what once was run. Examples of bouquet programming: an analysis script in support of a one-time plot, a scrappy proof-of-concept or a\n        <a target=\"_blank\" rel=\"noreferrer noopener\" href=\"https://en.wikipedia.org/wiki/Minimal_reproducible_example\">minimal reproducible example</a>.\n      </p><p>\n        Bouquet programming is still worth writing home about (!) and sharing generously in the same ways as houseplant programming‚Äîor agricultural programming!‚Äîbut is even  likely to work off-the-shelf for a new application\n        than houseplant code is, even if rerun by the same person who originally programmed it.\n      </p><h2>Bonus: Garden stakes for horticulturalist programmers</h2><p>I made a status badge for houseplant repos‚Äîfeel free to use it!</p><pre><code>&lt;a href=\"https://www.hannahilea.com/blog/houseplant-programming\"&gt;\n  &lt;img alt=\"Static Badge\" src=\"https://img.shields.io/badge/%F0%9F%AA%B4%20Houseplant%20-x?style=flat&amp;amp;label=Project%20type&amp;amp;color=1E1E1D\"&gt;\n&lt;/a&gt;</code></pre><p>And a bonus badge for bouquet programming:</p><pre><code>&lt;a href=\"https://www.hannahilea.com/blog/houseplant-programming\"&gt;\n  &lt;img alt=\"Static Badge\" src=\"https://img.shields.io/badge/&amp;#x1F490;%20Bouquet%20-x?style=flat&amp;amp;label=Project%20type&amp;amp;color=1E1E1D\"&gt;\n&lt;/a&gt;</code></pre><p><strong><em>Thanks to <a target=\"_blank\" rel=\"noreferrer noopener\" href=\"https://rygoldstein.com\">Ryan</a> for the coinage and to AF for introducing me to strategies for recognizing and countering perfectionism.</em></strong></p><ul><li>Tags: phytoid, houseplant-programming</li></ul>","contentLength":8822,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47181542"},{"title":"Hardwood: A New Parser for Apache Parquet","url":"https://www.morling.dev/blog/hardwood-new-parser-for-apache-parquet/","date":1772119899,"author":"rmoff","guid":181,"unread":true,"content":"<div><p>Hardwood is built with high performance in mind. It applies many of the lessons learned from <a href=\"https://github.com/gunnarmorling/1brc\">1BRC</a>, such as memory-mapping files or multi-threading. I am planning to share more details in a future blog post, so I‚Äôm going to focus just on one specific performance-related aspect here: Parallelizing the work of parsing Parquet files, so as to utilize the available CPU resources as much as possible and achieve high throughput.</p></div><div><p>This task is <a href=\"https://www.linkedin.com/posts/gunnar-morling_hardwood-activity-7421540936763129856-FCwD\">surprisingly complex</a> due to the subtleties of the format, so Hardwood pulls a few tricks for taking advantage of all the available cores:</p></div><div><ul><li><p>, fanning out the work of decoding individual data pages to multiple worker threads. This allows for a much higher CPU utilization (and lower memory consumption) than when solely processing different column chunks, row groups, or even files in parallel.</p></li><li><p><strong>Adaptive page prefetching</strong>, ensuring that columns which are slower to decode than others (e.g. depending on their data type) receive more resources, so that all columns of a file can be read at the same pace.</p></li><li><p>, starting to map and decode the pages of file N+1 when approaching the end of file N of a multi-file dataset, avoiding any slowdown at file transitions.</p></li></ul></div><div><p>By employing these techniques and some others, such as minimizing allocations and avoiding auto-boxing of primitive values, Hardwood‚Äôs performance has come quite a long way since starting the project at the end of last year. As an example, the values of three out of 20 columns of the <a href=\"https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page\">NYC taxi ride data set</a> (a subset of 119 files overall, ~9.2 GB total, ~650M rows) can be summed up in ~2.7 sec using the row reader API with indexed access on my MacBook Pro M3 Max with 16 CPU cores. With the column reader API, the same task takes ~1.2 sec.</p></div><div><p>The taxi ride data set has a completely flat schema, i.e. it doesn‚Äôt contain any structs, lists, or maps. Most Parquet-based data sets fall into this category, and thus the focus for optimizing Hardwood has primarily been on these kinds of files so far. While less commonly found, the Parquet format also supports nested schemas. An example for this category are the Parquet files of the <a href=\"https://docs.overturemaps.org/getting-data/\">Overture Maps</a> project. On the same machine as above, Hardwood can completely parse all the columns of a file with points of interest (~900 MB, ~9M records) in ~2.1 sec using the row reader API and in ~1.3 sec with the column reader API.</p></div><div><p>In order to identify bottlenecks, Hardwood comes with support for the JDK Flight Recorder, tracking key performance metrics and events such as prefetch misses, page decoding times, etc.</p></div><div><p>Further improving performance remains a key objective for the project going forward; to that end there are some first automated performance tests for flat and nested schemas and we are planning to set up an automated change detection pipeline using <a href=\"https://otava.apache.org/\">Apache Otava</a>, allowing us to detect any potential regressions early on.</p></div>","contentLength":2865,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47167432"},{"title":"H-Bomb: A Frank Lloyd Wright typographic mystery","url":"https://www.inconspicuous.info/p/h-bomb-a-frank-lloyd-wright-typographic","date":1772097537,"author":"mrngm","guid":180,"unread":true,"content":"<p><em></em></p><p><a href=\"https://en.wikipedia.org/wiki/Unity_Temple\" rel=\"\">Unity Temple</a><a href=\"https://www.architectureanddesign.com.au/editorial/features/frank-lloyd-wright-the-greatest-american-architect\" rel=\"\">said</a></p><p>Despite all of that, Unity Temple includes a surprising flaw. Can you spot it in that header photo?</p><p>Let‚Äôs zoom in on a section of the bronze lettering above the doors:</p><p><a href=\"https://www.inconspicuous.info/p/a-common-design-error-thats-been\" rel=\"\">are often upside-down</a><a href=\"https://jonathanhoefler.com/typefaces\" rel=\"\">famous typographer</a></p><p>I asked Jonathan if he said anything to the Unity Temple staff about the upside-down letter. ‚ÄúI didn‚Äôt have the heart,‚Äù he said. ‚ÄúAlso, what could be done?‚Äù</p><p>That might have been the end of the story. I imagined writing a short post that concluded with something like ‚ÄúHey, even Frank Lloyd Wright made mistakes!‚Äù</p><p><a href=\"https://en.wikipedia.org/wiki/Shotcrete\" rel=\"\">gunite</a></p><p>That was an intriguing thought, so I figured I‚Äôd try to find out if the letters had been temporarily removed as part of the 1970s gunite treatment. That was the start of what eventually became a lengthy research and reporting process. Along the way, I turned up a bunch of relevant information, including the following:</p><ul><li><p>Unity Temple has two separate entrances, one at the east and one at the west. Each entrance is adorned with identical metal lettering spelling out the same phrase: ‚ÄúFor the Worship of God and the Service of Man.‚Äù (Jonathan‚Äôs photos are of the western entrance, and he didn‚Äôt realize there‚Äôs an identical sign on the eastern side. If he had known, he would have checked the eastern ‚ÄúH‚Äù situation.)</p></li><li><p>Both signs were indeed removed for the gunite treatment and then reinstalled, just as Jonathan suspected. That was in 1973.</p></li><li><p><a href=\"https://www.cbsnews.com/chicago/news/46691/\" rel=\"\">thieves stole 58 of the 72 original letters</a></p></li><li><p><a href=\"https://chicago.curbed.com/2017/6/7/15751444/frank-lloyd-wright-architecture-unity-temple-restoraton\" rel=\"\">$25 million restoration</a></p></li></ul><p>This information cast Jonathan‚Äôs observation in a different light, because it means Unity Temple‚Äôs lettering ‚Äî which is rendered in a custom typeface that Wright designed ‚Äî has gone through at least four distinct eras:</p><p>Multiply each of the four eras by the three ‚ÄúH‚Äùs that appear in the slogan, and then again by the two separate entrances, and you have 24 distinct opportunities for an upside-down ‚ÄúH‚Äù to be installed! (And there could be even more eras, and thus more opportunities for inverted ‚ÄúH‚Äùs, if the letters were ever taken down and then reinstalled for some other reason that didn‚Äôt turn up in my research.)</p><p>So had the misoriented ‚ÄúH‚Äù that Jonathan recently spotted on the western sign been introduced as part of the recent restoration? Or maybe after the theft? Or maybe that ‚ÄúH‚Äù had been upside-down all along, and they just kept it that way with each reinstallation for the sake of consistency? Meanwhile, what about the lettering for the eastern entrance?</p><p>And most intriguingly: Had Frank Lloyd Wright himself ever been responsible for an upside-down ‚ÄúH‚Äù? Wright died in 1959, so he had nothing to do with the most recent iterations of the lettering, but what about the earlier time periods?</p><div data-attrs=\"{&quot;url&quot;:&quot;https://www.inconspicuous.info/p/h-bomb-a-frank-lloyd-wright-typographic?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;}\" data-component-name=\"CaptionedButtonToDOM\"><div><p>This post is public so feel free to share it.</p></div></div><p>My hope was to answer those questions by creating a comprehensive visual timeline of the lettering over both entrances, so I ended up doing a lot of photo research. Recent-ish photos of the building are fairly easy to find, especially on Flickr (a godsend, because Flickr pics are date-tagged). But older images ‚Äî basically, anything earlier than 2005 ‚Äî were surprisingly difficult to source. I ended up having to engage quite a bit with what I‚Äôve come to think of as the Frank Lloyd Wright industrial complex ‚Äî a dense bureaucracy of foundations, libraries, museums, and research institutions that control access to anything Wright-related.</p><p>While I didn‚Äôt achieve my original goal of producing a comprehensive visual record of the lettering, I did come up with a fair number of data points. Let‚Äôs start here:</p><p>Wright‚Äôs original drawings for Unity Temple, shown above, include depictions of the lettering. Let‚Äôs zoom in to get a closer look at the key area:</p><p>The drawing clearly shows that the crossbar of the ‚ÄúH‚Äù should be slightly north of the equator, so to speak, thus aligning with the center arm of the ‚ÄúE.‚Äù That‚Äôs not surprising, but it‚Äôs good to establish this as our baseline of Wright‚Äôs intent.</p><p>Unfortunately, I was not able to find any photos from Unity Temple‚Äôs 1908 opening, or even from its first few decades. The earliest archival photo I came up with is this one, which is frustratingly dated by the Oak Park Library as being from ‚Äú1930s-40s‚Äù:</p><p>Based on the shadows, that is the eastern entrance. The lettering isn‚Äôt easy to make out, so let‚Äôs zoom in again:</p><p>Although the image quality isn‚Äôt great, it‚Äôs good enough to confirm that each ‚ÄúH‚Äù is oriented correctly. For now, this is the earliest document we have.</p><p>So when was this photo taken? In another case of frustrating dating, the Chicago History Museum‚Äôs archive lists the date as ‚Äú1956-1978.‚Äù Although we can‚Äôt know for sure, I‚Äôm thinking this image was probably taken after the 1973 gunite treatment, which would explain the letter orientation changes.</p><p>Jumping ahead to the 2000s ‚Äî shortly prior to the 2010 theft ‚Äî Flickr photos show no changes to the western sign, which was still fully ‚ÄúH‚Äù-compliant and still had the upside-down ‚ÄúS.‚Äù Here are two representative examples, with the dates noted on each photo:</p><p>Photos of the eastern entrance from this period were harder to come by, in part because a tree was obscuring part of the sign. But in this 2007 shot, it appears that the ‚ÄúS‚Äù in ‚ÄúWORSHIP‚Äù is upside-down, as is the ‚ÄúH‚Äù on the second line (plus the ‚ÄúV‚Äù in ‚ÄúSERVICE‚Äù is missing, but that‚Äôs a separate issue):</p><p>That last photo doesn‚Äôt show the ‚ÄúTHE‚Äù in the top line. But the full slogan is visible in this 2008 shot:</p><p>So that confirms it: Shortly prior to the 2010 theft, the eastern sign had two upside-down letters ‚Äî an ‚ÄúH‚Äù and an ‚ÄúS.‚Äù</p><p>Vandals took most of the letters sometime during the night of September 28th, 2010. Here‚Äôs a photo showing how the denuded western entrance looked about nine and a half months later:</p><p>If we zoom in, the ghosted letters seem to confirm that each ‚ÄúH‚Äù was properly oriented and that the ‚ÄúS‚Äù on the top line was not:</p><p>I was not able to find a corresponding photo for the eastern sign.</p><p>Shiny new bronze lettering was unveiled in late May of 2012. How did it look? Let‚Äôs start with the western entrance:</p><p>Everything looks shipshape there ‚Äî no glitches. </p><p>But what about the eastern entrance, which previously had an inverted ‚ÄúH‚Äù and an inverted ‚ÄúS‚Äù? Let‚Äôs take a look:</p><p>They fixed both of the letters! (Looks like they also got rid of the tree, or at least pared it back significantly.)</p><p>So during this period ‚Äî after the 2010 theft, but before the 2014-17 restoration ‚Äî both signs were A-OK (or, if you prefer, H-OK).</p><p>Unity Temple was closed from mid-2014 to mid-2017 for a $25 million restoration that covered, according to one report I read, ‚Äúevery inch‚Äù of the facility. Did that include the lettering above the two entrances? Let‚Äôs start with the western side:</p><p>Oopsie. This error ‚Äî the upside-down ‚ÄúH‚Äù on the first ‚ÄúTHE‚Äù ‚Äî is the same glitch that Jonathan Hoefler recently spotted. So now we know when that mistake was introduced: as part of the 2014-17 restoration.</p><p>The eastern entrance, however, appears to have escaped unscathed:</p><p>Everything there looks good.</p><p>Did you follow all of that? Here‚Äôs a table summarizing what we have and haven‚Äôt learned:</p><p>I feel like that‚Äôs a good start on this project, although there‚Äôs a lot we still don‚Äôt know. Most crucially, it‚Äôs not clear whether Frank Lloyd Wright himself  oversaw the installation of any upside-down letters, although several other architectural professionals clearly did.</p><p>As it happens, I spoke to one of those professionals as part of my reporting. I‚Äôll have some thoughts from that person ‚Äî the man responsible for the current upside-down ‚ÄúH‚Äù that started us down this rabbit hole ‚Äî tomorrow. Stay tuned!</p><p><em>(Right-side-up thanks to Jonathan Hoefler for getting the ball rolling on this one.)</em></p><p><em><a href=\"mailto:plukas64@gmail.com\" rel=\"\">contact him here</a></em></p>","contentLength":7874,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47163779"},{"title":"The happiest I've ever been","url":"https://ben-mini.com/2026/the-happiest-ive-ever-been","date":1772079227,"author":"bewal416","guid":179,"unread":true,"content":"<p>It was around January 2020. I became the head coach of a youth basketball team.</p><p>I was a few months into my first job out of college, and I was feeling‚Ä¶ empty. I couldn‚Äôt explain why, so I set out to fill the void. I built side projects, went drinking with coworkers, and got really into the upcoming election. These all felt like things I  be doing as the <a href=\"https://www.urbandictionary.com/define.php?term=yuppy\" target=\"_blank\" rel=\"noopener noreferrer\">yuppy</a> I had just become, but the emptiness resided.</p><p>Indiana loves its basketball, so it was easy for me to find a local gym to play pickup. I became friendly with the regulars and the staff. One day, the athletic director told me they were looking for a volunteer assistant basketball coach for the middle school league. Being a former camp counselor, the idea intrigued me. Unexpectedly, the ‚Äúassistant‚Äù position became the ‚Äúhead‚Äù position, and I was quickly thrown into a clinic, where I had to draft all my players by the end of the session.</p><p>Team drafted. 6 kids. 1 game per week. 2 practices per week. 14 parent emails (somehow). Practice starts tomorrow.</p><p>You know those bullshit leadership positions we all had in high school and college? Like how you were ‚ÄúVP of Operations‚Äù for some club, and all you did was order pizza? Yeah, this was not that. Getting thrown into an empty gym with six kids and two basketballs is a thrilling experience! I‚Äôm so grateful my buddy Clayton joined me as co-coach. I spent the whole day preparing for that 2-hour practice, and I think it showed. We learned each other‚Äôs names, had a solid skills assessment, set some ground rules, and had some fun with a little knockout.</p><p>Here‚Äôs the headline: I fucking loved being a coach. And, I don‚Äôt want to brag, <em>but I was really good at it</em>. We lost one game, our first game, and went undefeated after that. But improving each kid‚Äôs skill and confidence was the real mission. Instead of my desk job, I‚Äôd be asking Clayton how we could make Corey¬π use his body for rebounding. Or how Monte‚Äôs soccer skills could be best leveraged. Or how Evan, our best player, could become an on-court leader.</p><p>David, our self-deprecating goofball who insisted he‚Äôd be benched in the 4th quarter, made  for the ball in our last game. At the end of every game, I‚Äôd ask if anyone had any shoutouts to give about their teammates. Evan called David ‚Äúa beast‚Äù for his dives, followed by rousing applause from the whole team. David‚Äôs smile is likely something I‚Äôll be taking to my grave.</p><p>As the kids‚Äô confidence grew, mine did too. I walked around the gym with a strut. I greeted their families with confident eye contact, remembering every word they said. I felt myself performing better in all parts of life: work, community, relationships‚Ä¶ I became ‚Äúthat guy‚Äù who made shit happen in our friend group.</p><p>Heading into March, I was planning a surprise for the team. I had a contact at the Indiana Pacers, and I was scheming to get them to play on the court during a break in play. But to much ruin, Covid became a pandemic, leading to an abrupt end to the season, and an immediate global quarantine‚Ä¶</p><p>But that‚Äôs another story for another time. This is a story about happiness- and finding it at any point in your life.</p><p>I was happy when I was a youth basketball coach. And I find it notable to recall  I was happy:</p><ul><li>I  helping kids. I can‚Äôt exactly explain why‚Ä¶ perhaps it‚Äôs biological. But I‚Äôm pretty darn good at it. I find it much easier to talk to kids than adults.</li><li>I  being in the real world. If I taught those kids on Zoom‚Ä¶ it wouldn‚Äôt have been the same. To travel somewhere, break a sweat, and high-five my team was such a gift.</li><li>I  being in control. Coordinating practice, calling the plays, making substitutions- coaching let me steer my own ship. ‚ÄúLoving control‚Äù has its drawbacks. But succeeding within that control gave me real confidence and belief in myself.</li><li>I  basketball. I can‚Äôt think of a better activity to learn about your mind, body, and role within a system. I‚Äôm a junkyard dog. When I get mad, I work extra hard doing the stuff nobody else wants to do. But I lose energy faster. I learned this from the game.</li></ul><p>If I could give any advice to someone who needs it, I‚Äôd tell them to write down the things that have made them happy, and then explore .</p><p>Why am I writing this now? I have a sense that many people in tech are feeling what I‚Äôm feeling. For years, you‚Äôve sat in front of a rectangle, moving tinier rectangles, only to learn that AI can now move those rectangles 10x better. As someone outside the equity class, you begin to wonder what your role is in this new paradigm. And whether rectangles were ever your ticket to happiness in the first place.</p><p>When I was the age my basketball kids were,  came out. Like so many, I am a product of that generation. I accepted the propaganda that my value to this world only went as far as my product could scale. At 28, I‚Äôm finally beginning to challenge that.</p><p>Don‚Äôt get me wrong, I love tech. <a href=\"https://ben-mini.com/2024/the-most-mind-blowing-tech-moments-of-my-life\">I think it‚Äôs magical</a>. But I really hope to live in a world where my future kids find sitting in front of a rectangle all day to be dystopian and cringe. I really really really hope the invisible hand finds its way to getting me back into something I love. Maybe this ‚Äúdeath of SaaS‚Äù talk, regardless of truth, is the wakeup call to so many us need.</p><p>¬π Names have been changed to protect their privacy.</p>","contentLength":5340,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47161759"},{"title":"Woxi: Wolfram Mathematica Reimplementation in Rust","url":"https://github.com/ad-si/Woxi","date":1772043886,"author":"adamnemecek","guid":178,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=47155526"}],"tags":["dev"]}